<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://cdekort.github.io/github-search-rss/dinov3-repos.rss</id>
    <title>DINOv3 Repositories</title>
    <updated>2026-02-24T00:31:42.493Z</updated>
    <generator>github-search-rss</generator>
    <link rel="alternate" href="https://cdekort.github.io/github-search-rss/dinov3-repos.rss"/>
    <subtitle>DINOv3 Repositories on GitHub</subtitle>
    <rights>github-search-rss</rights>
    <entry>
        <title type="html"><![CDATA[Abigail-amk/AI-training: ü§ñ Enhance programming education by fine-tuning the Phi-3 Mini model to deliver well-structured, documented code responses, ensuring best practices in coding.]]></title>
        <id>https://github.com/Abigail-amk/AI-training</id>
        <link href="https://github.com/Abigail-amk/AI-training"/>
        <updated>2026-02-23T23:30:42.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/204875701?v=4" width="64" height="64" alt=""/><br/><div>ü§ñ Enhance programming education by fine-tuning the Phi-3 Mini model to deliver well-structured, documented code responses, ensuring best practices in coding.</div>]]></content>
        <author>
            <name>Abigail-amk</name>
            <email>Abigail-amk@noreply.github.com</email>
            <uri>https://github.com/Abigail-amk</uri>
        </author>
        <published>2026-02-15T00:26:11.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nacho4412gg/dinov3]]></title>
        <id>https://github.com/Nacho4412gg/dinov3</id>
        <link href="https://github.com/Nacho4412gg/dinov3"/>
        <updated>2026-02-23T23:06:16.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/204909044?v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>Nacho4412gg</name>
            <email>Nacho4412gg@noreply.github.com</email>
            <uri>https://github.com/Nacho4412gg</uri>
        </author>
        <published>2026-01-11T18:24:22.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[dlidgett/AD-DINOv3: üîç Enhance anomaly detection with AD-DINOv3, a framework adapting DINOv3 for zero-shot scenarios through advanced calibration techniques.]]></title>
        <id>https://github.com/dlidgett/AD-DINOv3</id>
        <link href="https://github.com/dlidgett/AD-DINOv3"/>
        <updated>2026-02-23T22:11:52.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/66205403?v=4" width="64" height="64" alt=""/><br/><div>üîç Enhance anomaly detection with AD-DINOv3, a framework adapting DINOv3 for zero-shot scenarios through advanced calibration techniques.</div>]]></content>
        <author>
            <name>dlidgett</name>
            <email>dlidgett@noreply.github.com</email>
            <uri>https://github.com/dlidgett</uri>
        </author>
        <published>2020-05-31T11:42:52.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[pierrelgol/tea-ai: DinoV3-Yolo26-Pipeline]]></title>
        <id>https://github.com/pierrelgol/tea-ai</id>
        <link href="https://github.com/pierrelgol/tea-ai"/>
        <updated>2026-02-23T21:12:17.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/119697612?u=37a68a08bbf84ef9c713ac3f5ae7f32998c2e54e&v=4" width="64" height="64" alt=""/><br/><div>DinoV3-Yolo26-Pipeline</div>]]></content>
        <author>
            <name>pierrelgol</name>
            <email>pierrelgol@noreply.github.com</email>
            <uri>https://github.com/pierrelgol</uri>
        </author>
        <published>2026-02-22T10:58:01.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[lightly-ai/lightly-train: All-in-one training for vision models (YOLO, ViTs, RT-DETR, DINOv3): pretraining, fine-tuning, distillation.]]></title>
        <id>https://github.com/lightly-ai/lightly-train</id>
        <link href="https://github.com/lightly-ai/lightly-train"/>
        <updated>2026-02-23T17:51:45.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/50146475?v=4" width="64" height="64" alt=""/><br/><div>All-in-one training for vision models (YOLO, ViTs, RT-DETR, DINOv3): pretraining, fine-tuning, distillation.</div>]]></content>
        <author>
            <name>lightly-ai</name>
            <email>lightly-ai@noreply.github.com</email>
            <uri>https://github.com/lightly-ai</uri>
        </author>
        <published>2025-04-10T08:23:51.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[lrnzslrn83/Few-Shot-Classification-on-LIVECell-using-DINOv3-Embeddings: Questo progetto implementa un framework di few-shot learning per la classificazione di immagini cellulari del dataset LIVECell utilizzando embedding estratti da DINOv3, un Vision Transformer pre-addestrato in modalit√† self-supervised.]]></title>
        <id>https://github.com/lrnzslrn83/Few-Shot-Classification-on-LIVECell-using-DINOv3-Embeddings</id>
        <link href="https://github.com/lrnzslrn83/Few-Shot-Classification-on-LIVECell-using-DINOv3-Embeddings"/>
        <updated>2026-02-23T11:03:36.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/200913309?v=4" width="64" height="64" alt=""/><br/><div>Questo progetto implementa un framework di few-shot learning per la classificazione di immagini cellulari del dataset LIVECell utilizzando embedding estratti da DINOv3, un Vision Transformer pre-addestrato in modalit√† self-supervised.</div>]]></content>
        <author>
            <name>lrnzslrn83</name>
            <email>lrnzslrn83@noreply.github.com</email>
            <uri>https://github.com/lrnzslrn83</uri>
        </author>
        <published>2026-02-23T10:51:59.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[qqaazz0222/VICET: VICET is a deep learning project that utilizes a DINOv3-based Transformer model to virtually generate contrast-enhanced effects similar to Contrast-Enhanced CT (CECT) from Non-Contrast CT (NCCT) images.]]></title>
        <id>https://github.com/qqaazz0222/VICET</id>
        <link href="https://github.com/qqaazz0222/VICET"/>
        <updated>2026-02-23T06:16:11.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/39234389?u=ae80636b15492f4c8daf4ae3db5b0914b590513d&v=4" width="64" height="64" alt=""/><br/><div>VICET is a deep learning project that utilizes a DINOv3-based Transformer model to virtually generate contrast-enhanced effects similar to Contrast-Enhanced CT (CECT) from Non-Contrast CT (NCCT) images.</div>]]></content>
        <author>
            <name>qqaazz0222</name>
            <email>qqaazz0222@noreply.github.com</email>
            <uri>https://github.com/qqaazz0222</uri>
        </author>
        <published>2026-02-18T06:10:52.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nacho4412gg/nacho4412gg.github.io: ü¶ñ Explore DINOv3, a state-of-the-art backbone for computer vision models, now integrated with Hugging Face and PyTorch for enhanced performance and flexibility.]]></title>
        <id>https://github.com/Nacho4412gg/nacho4412gg.github.io</id>
        <link href="https://github.com/Nacho4412gg/nacho4412gg.github.io"/>
        <updated>2026-02-22T19:04:07.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/204909044?v=4" width="64" height="64" alt=""/><br/><div>ü¶ñ Explore DINOv3, a state-of-the-art backbone for computer vision models, now integrated with Hugging Face and PyTorch for enhanced performance and flexibility.</div>]]></content>
        <author>
            <name>Nacho4412gg</name>
            <email>Nacho4412gg@noreply.github.com</email>
            <uri>https://github.com/Nacho4412gg</uri>
        </author>
        <published>2026-01-11T18:30:14.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[JasonTzimas/DINOv3-powered-YOLOv11: An optimized Distillation pipeline for Knowledge-Transfer between DINOv3 and YOLOv11]]></title>
        <id>https://github.com/JasonTzimas/DINOv3-powered-YOLOv11</id>
        <link href="https://github.com/JasonTzimas/DINOv3-powered-YOLOv11"/>
        <updated>2026-02-22T11:19:19.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/76654609?v=4" width="64" height="64" alt=""/><br/><div>An optimized Distillation pipeline for Knowledge-Transfer between DINOv3 and YOLOv11</div>]]></content>
        <author>
            <name>JasonTzimas</name>
            <email>JasonTzimas@noreply.github.com</email>
            <uri>https://github.com/JasonTzimas</uri>
        </author>
        <published>2026-02-22T11:19:15.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[jaychempan/V2-SAM: [CVPR'26] Official Code for ‚ÄúV¬≤-SAM: Marrying SAM2 with Multi-Prompt Experts for Cross-View Object Correspondence‚Äù]]></title>
        <id>https://github.com/jaychempan/V2-SAM</id>
        <link href="https://github.com/jaychempan/V2-SAM"/>
        <updated>2026-02-23T13:05:34.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/74408955?u=7500f66b0d147f3e1a9b035dc5dcce7f30abeaae&v=4" width="64" height="64" alt=""/><br/><div>[CVPR'26] Official Code for ‚ÄúV¬≤-SAM: Marrying SAM2 with Multi-Prompt Experts for Cross-View Object Correspondence‚Äù</div>]]></content>
        <author>
            <name>jaychempan</name>
            <email>jaychempan@noreply.github.com</email>
            <uri>https://github.com/jaychempan</uri>
        </author>
        <published>2025-12-10T14:01:47.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[ArtemVerbov/Dinov3-For-Semantic-Segmentation: Dinov3 backbone adopted for semantic segmentation.]]></title>
        <id>https://github.com/ArtemVerbov/Dinov3-For-Semantic-Segmentation</id>
        <link href="https://github.com/ArtemVerbov/Dinov3-For-Semantic-Segmentation"/>
        <updated>2026-02-21T14:12:59.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/59263685?u=644171ead2758667b101b888269925d338b05ff4&v=4" width="64" height="64" alt=""/><br/><div>Dinov3 backbone adopted for semantic segmentation.</div>]]></content>
        <author>
            <name>ArtemVerbov</name>
            <email>ArtemVerbov@noreply.github.com</email>
            <uri>https://github.com/ArtemVerbov</uri>
        </author>
        <published>2026-01-25T07:01:47.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[JordiCan/galaxy_image_classifier: A deep learning pipeline for classifying galaxy morphologies from the Galaxy Zoo 2 dataset. It leverages the Hugging Face ecosystem to fine-tune state-of-the-art vision models using Parameter-Efficient Fine-Tuning (PEFT) techniques.]]></title>
        <id>https://github.com/JordiCan/galaxy_image_classifier</id>
        <link href="https://github.com/JordiCan/galaxy_image_classifier"/>
        <updated>2026-02-21T11:49:06.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/90319800?u=3c3ff160ac34fc527751da1e443dc3c83e3c0a31&v=4" width="64" height="64" alt=""/><br/><div>A deep learning pipeline for classifying galaxy morphologies from the Galaxy Zoo 2 dataset. It leverages the Hugging Face ecosystem to fine-tune state-of-the-art vision models using Parameter-Efficient Fine-Tuning (PEFT) techniques.</div>]]></content>
        <author>
            <name>JordiCan</name>
            <email>JordiCan@noreply.github.com</email>
            <uri>https://github.com/JordiCan</uri>
        </author>
        <published>2025-09-27T12:26:13.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[enot-style/imbeddings: A minimal FastAPI service for generating image embeddings using Hugging Face Vision Transformer models.]]></title>
        <id>https://github.com/enot-style/imbeddings</id>
        <link href="https://github.com/enot-style/imbeddings"/>
        <updated>2026-02-20T06:46:07.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/260076530?v=4" width="64" height="64" alt=""/><br/><div>A minimal FastAPI service for generating image embeddings using Hugging Face Vision Transformer models.</div>]]></content>
        <author>
            <name>enot-style</name>
            <email>enot-style@noreply.github.com</email>
            <uri>https://github.com/enot-style</uri>
        </author>
        <published>2026-01-08T21:52:55.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[grenademeister/mrfm-dino: DINOv3 based MRI foundation model]]></title>
        <id>https://github.com/grenademeister/mrfm-dino</id>
        <link href="https://github.com/grenademeister/mrfm-dino"/>
        <updated>2026-02-20T02:36:31.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/83631703?v=4" width="64" height="64" alt=""/><br/><div>DINOv3 based MRI foundation model</div>]]></content>
        <author>
            <name>grenademeister</name>
            <email>grenademeister@noreply.github.com</email>
            <uri>https://github.com/grenademeister</uri>
        </author>
        <published>2026-02-20T02:36:16.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[jinlab-imvr/DINOv3-FD: [2026 MIDL]"Incentivizing DINOv3 Adaptation for Medical Vision Tasks via Feature Disentanglement"]]></title>
        <id>https://github.com/jinlab-imvr/DINOv3-FD</id>
        <link href="https://github.com/jinlab-imvr/DINOv3-FD"/>
        <updated>2026-02-19T14:17:19.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/163241502?v=4" width="64" height="64" alt=""/><br/><div>[2026 MIDL]"Incentivizing DINOv3 Adaptation for Medical Vision Tasks via Feature Disentanglement"</div>]]></content>
        <author>
            <name>jinlab-imvr</name>
            <email>jinlab-imvr@noreply.github.com</email>
            <uri>https://github.com/jinlab-imvr</uri>
        </author>
        <published>2025-11-29T12:33:45.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[anastasiia-popova/compressed-medvision-classifier: Post-training INT8 quantization and pruning for a DINOv3 ConvNeXt-Tiny MedMNIST classifier, optimized for CPU inference]]></title>
        <id>https://github.com/anastasiia-popova/compressed-medvision-classifier</id>
        <link href="https://github.com/anastasiia-popova/compressed-medvision-classifier"/>
        <updated>2026-02-19T11:02:34.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/119516973?u=917229a4ec5343c28a54078b5489b129b10f528d&v=4" width="64" height="64" alt=""/><br/><div>Post-training INT8 quantization and pruning for a DINOv3 ConvNeXt-Tiny MedMNIST classifier, optimized for CPU inference</div>]]></content>
        <author>
            <name>anastasiia-popova</name>
            <email>anastasiia-popova@noreply.github.com</email>
            <uri>https://github.com/anastasiia-popova</uri>
        </author>
        <published>2026-01-26T16:36:46.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[GIS-Remote-Sensing-Goettingen/dinov3-LWF-Segmentation-erosion]]></title>
        <id>https://github.com/GIS-Remote-Sensing-Goettingen/dinov3-LWF-Segmentation-erosion</id>
        <link href="https://github.com/GIS-Remote-Sensing-Goettingen/dinov3-LWF-Segmentation-erosion"/>
        <updated>2026-02-18T19:09:09.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/231213492?v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>GIS-Remote-Sensing-Goettingen</name>
            <email>GIS-Remote-Sensing-Goettingen@noreply.github.com</email>
            <uri>https://github.com/GIS-Remote-Sensing-Goettingen</uri>
        </author>
        <published>2026-01-26T13:43:19.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[GIS-Remote-Sensing-Goettingen/Dinov3-LWF-Segmentation]]></title>
        <id>https://github.com/GIS-Remote-Sensing-Goettingen/Dinov3-LWF-Segmentation</id>
        <link href="https://github.com/GIS-Remote-Sensing-Goettingen/Dinov3-LWF-Segmentation"/>
        <updated>2026-02-18T10:30:34.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/231213492?v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>GIS-Remote-Sensing-Goettingen</name>
            <email>GIS-Remote-Sensing-Goettingen@noreply.github.com</email>
            <uri>https://github.com/GIS-Remote-Sensing-Goettingen</uri>
        </author>
        <published>2026-02-02T13:58:10.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[facebookresearch/dinov3: Reference PyTorch implementation and models for DINOv3]]></title>
        <id>https://github.com/facebookresearch/dinov3</id>
        <link href="https://github.com/facebookresearch/dinov3"/>
        <updated>2026-02-23T22:44:29.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/16943930?v=4" width="64" height="64" alt=""/><br/><div>Reference PyTorch implementation and models for DINOv3</div>]]></content>
        <author>
            <name>facebookresearch</name>
            <email>facebookresearch@noreply.github.com</email>
            <uri>https://github.com/facebookresearch</uri>
        </author>
        <published>2025-08-07T14:11:34.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[gtom-pandas/image2biomass: My solution for Kaggle CSIRO Image2Biomass Challenge]]></title>
        <id>https://github.com/gtom-pandas/image2biomass</id>
        <link href="https://github.com/gtom-pandas/image2biomass"/>
        <updated>2026-02-17T12:00:09.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/228737540?u=7df296779ddf735d9c87f5de6a614b569ec88c5d&v=4" width="64" height="64" alt=""/><br/><div>My solution for Kaggle CSIRO Image2Biomass Challenge</div>]]></content>
        <author>
            <name>gtom-pandas</name>
            <email>gtom-pandas@noreply.github.com</email>
            <uri>https://github.com/gtom-pandas</uri>
        </author>
        <published>2026-02-03T19:24:51.000Z</published>
    </entry>
</feed>