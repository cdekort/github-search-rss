<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://cdekort.github.io/github-search-rss/dinov3-repos.rss</id>
    <title>DINOv3 Repositories</title>
    <updated>2026-02-27T00:33:16.352Z</updated>
    <generator>github-search-rss</generator>
    <link rel="alternate" href="https://cdekort.github.io/github-search-rss/dinov3-repos.rss"/>
    <subtitle>DINOv3 Repositories on GitHub</subtitle>
    <rights>github-search-rss</rights>
    <entry>
        <title type="html"><![CDATA[Abigail-amk/AI-training: ü§ñ Enhance programming education by fine-tuning the Phi-3 Mini model to deliver well-structured, documented code responses, ensuring best practices in coding.]]></title>
        <id>https://github.com/Abigail-amk/AI-training</id>
        <link href="https://github.com/Abigail-amk/AI-training"/>
        <updated>2026-02-26T22:18:55.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/204875701?v=4" width="64" height="64" alt=""/><br/><div>ü§ñ Enhance programming education by fine-tuning the Phi-3 Mini model to deliver well-structured, documented code responses, ensuring best practices in coding.</div>]]></content>
        <author>
            <name>Abigail-amk</name>
            <email>Abigail-amk@noreply.github.com</email>
            <uri>https://github.com/Abigail-amk</uri>
        </author>
        <published>2026-02-15T00:26:11.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nacho4412gg/dinov3]]></title>
        <id>https://github.com/Nacho4412gg/dinov3</id>
        <link href="https://github.com/Nacho4412gg/dinov3"/>
        <updated>2026-02-26T21:51:15.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/204909044?v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>Nacho4412gg</name>
            <email>Nacho4412gg@noreply.github.com</email>
            <uri>https://github.com/Nacho4412gg</uri>
        </author>
        <published>2026-01-11T18:24:22.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[yifangao112/DinoUNet: Official repository for Dino U-Net: Exploiting High-Fidelity Dense Features from Foundation Models for Medical Image Segmentation. (DINOv3)]]></title>
        <id>https://github.com/yifangao112/DinoUNet</id>
        <link href="https://github.com/yifangao112/DinoUNet"/>
        <updated>2026-02-26T21:07:20.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/108782764?u=ddbd92505579ca033fb62d41b61d3581b0c48782&v=4" width="64" height="64" alt=""/><br/><div>Official repository for Dino U-Net: Exploiting High-Fidelity Dense Features from Foundation Models for Medical Image Segmentation. (DINOv3)</div>]]></content>
        <author>
            <name>yifangao112</name>
            <email>yifangao112@noreply.github.com</email>
            <uri>https://github.com/yifangao112</uri>
        </author>
        <published>2025-08-27T23:00:58.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[dlidgett/AD-DINOv3: üîç Enhance anomaly detection with AD-DINOv3, a framework adapting DINOv3 for zero-shot scenarios through advanced calibration techniques.]]></title>
        <id>https://github.com/dlidgett/AD-DINOv3</id>
        <link href="https://github.com/dlidgett/AD-DINOv3"/>
        <updated>2026-02-26T20:50:22.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/66205403?v=4" width="64" height="64" alt=""/><br/><div>üîç Enhance anomaly detection with AD-DINOv3, a framework adapting DINOv3 for zero-shot scenarios through advanced calibration techniques.</div>]]></content>
        <author>
            <name>dlidgett</name>
            <email>dlidgett@noreply.github.com</email>
            <uri>https://github.com/dlidgett</uri>
        </author>
        <published>2020-05-31T11:42:52.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Phasurab/Traffic-Analysis-System: A fully containerized AI traffic analysis web app using FastAPI, OpenCV, and YOLOv8/DINOv3_convnext_ltdetr_tiny. Orchestrated with Docker Compose for seamless deployment and SQLite persistence.]]></title>
        <id>https://github.com/Phasurab/Traffic-Analysis-System</id>
        <link href="https://github.com/Phasurab/Traffic-Analysis-System"/>
        <updated>2026-02-26T19:47:02.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/184936763?u=ee4367d047fd9f716f531f26fc96695365e35ac0&v=4" width="64" height="64" alt=""/><br/><div>A fully containerized AI traffic analysis web app using FastAPI, OpenCV, and YOLOv8/DINOv3_convnext_ltdetr_tiny. Orchestrated with Docker Compose for seamless deployment and SQLite persistence.</div>]]></content>
        <author>
            <name>Phasurab</name>
            <email>Phasurab@noreply.github.com</email>
            <uri>https://github.com/Phasurab</uri>
        </author>
        <published>2026-02-26T15:19:03.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[LuizScarlet/AEIC: [CVPR 2026] Ultra-Low Bitrate Perceptual Image Compression with Shallow Encoder]]></title>
        <id>https://github.com/LuizScarlet/AEIC</id>
        <link href="https://github.com/LuizScarlet/AEIC"/>
        <updated>2026-02-26T12:05:58.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/79390474?u=d16d3b4a5527a411fa1c5f9cdca549af0ab24172&v=4" width="64" height="64" alt=""/><br/><div>[CVPR 2026] Ultra-Low Bitrate Perceptual Image Compression with Shallow Encoder</div>]]></content>
        <author>
            <name>LuizScarlet</name>
            <email>LuizScarlet@noreply.github.com</email>
            <uri>https://github.com/LuizScarlet</uri>
        </author>
        <published>2026-02-26T11:18:03.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[gaiadifilippo/Anatomically-Relevant-Frame-Selection-in-Laryngeal-Endoscopy: This repository contains code for classifying laryngeal endoscopic frames as anatomically relevant or not using DINOv3 embeddings and a trainable MLP. Includes interactive Jupyter widgets for active learning annotation to finetune the model to new dataset]]></title>
        <id>https://github.com/gaiadifilippo/Anatomically-Relevant-Frame-Selection-in-Laryngeal-Endoscopy</id>
        <link href="https://github.com/gaiadifilippo/Anatomically-Relevant-Frame-Selection-in-Laryngeal-Endoscopy"/>
        <updated>2026-02-26T10:43:33.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/215035633?v=4" width="64" height="64" alt=""/><br/><div>This repository contains code for classifying laryngeal endoscopic frames as anatomically relevant or not using DINOv3 embeddings and a trainable MLP. Includes interactive Jupyter widgets for active learning annotation to finetune the model to new dataset</div>]]></content>
        <author>
            <name>gaiadifilippo</name>
            <email>gaiadifilippo@noreply.github.com</email>
            <uri>https://github.com/gaiadifilippo</uri>
        </author>
        <published>2026-02-25T11:34:01.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Thanghuynh2808/Retail-Insight-Pipeline: Automated Planogram Compliance system for retail shelves. Features: Panorama Stitching, Zero-shot SKU Detection (YOLO, DINOv3, LightGlue), and LLM-powered rule validation. Optimized for large-scale grocery shelf analysis in Vietnam.]]></title>
        <id>https://github.com/Thanghuynh2808/Retail-Insight-Pipeline</id>
        <link href="https://github.com/Thanghuynh2808/Retail-Insight-Pipeline"/>
        <updated>2026-02-26T05:22:38.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/156525690?u=859091d4e8fe94e40ba8c4ba1324563f3228fda3&v=4" width="64" height="64" alt=""/><br/><div>Automated Planogram Compliance system for retail shelves. Features: Panorama Stitching, Zero-shot SKU Detection (YOLO, DINOv3, LightGlue), and LLM-powered rule validation. Optimized for large-scale grocery shelf analysis in Vietnam.</div>]]></content>
        <author>
            <name>Thanghuynh2808</name>
            <email>Thanghuynh2808@noreply.github.com</email>
            <uri>https://github.com/Thanghuynh2808</uri>
        </author>
        <published>2026-02-03T02:40:51.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[BeibeiIsFreshman/DINOv3_SAM: Knowledge Distillation from DINOv3-Guided SAM for Lightweight Underwater Salient Object Detection]]></title>
        <id>https://github.com/BeibeiIsFreshman/DINOv3_SAM</id>
        <link href="https://github.com/BeibeiIsFreshman/DINOv3_SAM"/>
        <updated>2026-02-26T02:02:09.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/146430099?v=4" width="64" height="64" alt=""/><br/><div>Knowledge Distillation from DINOv3-Guided SAM for Lightweight Underwater Salient Object Detection</div>]]></content>
        <author>
            <name>BeibeiIsFreshman</name>
            <email>BeibeiIsFreshman@noreply.github.com</email>
            <uri>https://github.com/BeibeiIsFreshman</uri>
        </author>
        <published>2025-12-09T06:49:32.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[lightly-ai/lightly-train: All-in-one training for vision models (YOLO, ViTs, RT-DETR, DINOv3): pretraining, fine-tuning, distillation.]]></title>
        <id>https://github.com/lightly-ai/lightly-train</id>
        <link href="https://github.com/lightly-ai/lightly-train"/>
        <updated>2026-02-26T15:51:18.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/50146475?v=4" width="64" height="64" alt=""/><br/><div>All-in-one training for vision models (YOLO, ViTs, RT-DETR, DINOv3): pretraining, fine-tuning, distillation.</div>]]></content>
        <author>
            <name>lightly-ai</name>
            <email>lightly-ai@noreply.github.com</email>
            <uri>https://github.com/lightly-ai</uri>
        </author>
        <published>2025-04-10T08:23:51.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[worship93keypad/dinov3]]></title>
        <id>https://github.com/worship93keypad/dinov3</id>
        <link href="https://github.com/worship93keypad/dinov3"/>
        <updated>2026-02-25T14:05:10.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/259578465?v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>worship93keypad</name>
            <email>worship93keypad@noreply.github.com</email>
            <uri>https://github.com/worship93keypad</uri>
        </author>
        <published>2026-02-25T14:03:16.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Killuazyt/ChangVitDinov3: dinoV3  16ÁöÑÈÄÇÈÖç]]></title>
        <id>https://github.com/Killuazyt/ChangVitDinov3</id>
        <link href="https://github.com/Killuazyt/ChangVitDinov3"/>
        <updated>2026-02-25T12:34:56.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/67639242?u=dbeef5de4d3e32ecc3c786929417e21429b2c649&v=4" width="64" height="64" alt=""/><br/><div>dinoV3  16ÁöÑÈÄÇÈÖç</div>]]></content>
        <author>
            <name>Killuazyt</name>
            <email>Killuazyt@noreply.github.com</email>
            <uri>https://github.com/Killuazyt</uri>
        </author>
        <published>2026-02-25T12:05:34.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[pierrelgol/tea-ai: DinoV3-Yolo26-Pipeline]]></title>
        <id>https://github.com/pierrelgol/tea-ai</id>
        <link href="https://github.com/pierrelgol/tea-ai"/>
        <updated>2026-02-24T23:30:25.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/119697612?u=37a68a08bbf84ef9c713ac3f5ae7f32998c2e54e&v=4" width="64" height="64" alt=""/><br/><div>DinoV3-Yolo26-Pipeline</div>]]></content>
        <author>
            <name>pierrelgol</name>
            <email>pierrelgol@noreply.github.com</email>
            <uri>https://github.com/pierrelgol</uri>
        </author>
        <published>2026-02-22T10:58:01.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[violayhho/DinoX-Ray: Chest X-Ray perception pipeline using DINOv3. Demonstrates lightweight decoders with frozen foundation backbones for both image classification (COVID vs. Healthy) and semantic segmentation (Lung Masking) in PyTorch.]]></title>
        <id>https://github.com/violayhho/DinoX-Ray</id>
        <link href="https://github.com/violayhho/DinoX-Ray"/>
        <updated>2026-02-24T20:15:15.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/143129517?u=08c01ddda9b18b64df039f0ac35a626c7a65c38d&v=4" width="64" height="64" alt=""/><br/><div>Chest X-Ray perception pipeline using DINOv3. Demonstrates lightweight decoders with frozen foundation backbones for both image classification (COVID vs. Healthy) and semantic segmentation (Lung Masking) in PyTorch.</div>]]></content>
        <author>
            <name>violayhho</name>
            <email>violayhho@noreply.github.com</email>
            <uri>https://github.com/violayhho</uri>
        </author>
        <published>2026-02-24T20:08:38.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[jseobyun/FaceDepth: DINOv3 based head depth estimation]]></title>
        <id>https://github.com/jseobyun/FaceDepth</id>
        <link href="https://github.com/jseobyun/FaceDepth"/>
        <updated>2026-02-24T08:52:16.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/53433086?u=165b43703aaa3163f65d4093a90f6ac2ce9473f1&v=4" width="64" height="64" alt=""/><br/><div>DINOv3 based head depth estimation</div>]]></content>
        <author>
            <name>jseobyun</name>
            <email>jseobyun@noreply.github.com</email>
            <uri>https://github.com/jseobyun</uri>
        </author>
        <published>2025-09-15T09:13:54.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[jseobyun/FaceParsing: DINOv3 based face parsing network]]></title>
        <id>https://github.com/jseobyun/FaceParsing</id>
        <link href="https://github.com/jseobyun/FaceParsing"/>
        <updated>2026-02-24T07:20:19.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/53433086?u=165b43703aaa3163f65d4093a90f6ac2ce9473f1&v=4" width="64" height="64" alt=""/><br/><div>DINOv3 based face parsing network</div>]]></content>
        <author>
            <name>jseobyun</name>
            <email>jseobyun@noreply.github.com</email>
            <uri>https://github.com/jseobyun</uri>
        </author>
        <published>2025-09-04T02:10:31.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[lrnzslrn83/Few-Shot-Classification-on-LIVECell-using-DINOv3-Embeddings: Questo progetto implementa un framework di few-shot learning per la classificazione di immagini cellulari del dataset LIVECell utilizzando embedding estratti da DINOv3, un Vision Transformer pre-addestrato in modalit√† self-supervised.]]></title>
        <id>https://github.com/lrnzslrn83/Few-Shot-Classification-on-LIVECell-using-DINOv3-Embeddings</id>
        <link href="https://github.com/lrnzslrn83/Few-Shot-Classification-on-LIVECell-using-DINOv3-Embeddings"/>
        <updated>2026-02-23T11:03:36.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/200913309?v=4" width="64" height="64" alt=""/><br/><div>Questo progetto implementa un framework di few-shot learning per la classificazione di immagini cellulari del dataset LIVECell utilizzando embedding estratti da DINOv3, un Vision Transformer pre-addestrato in modalit√† self-supervised.</div>]]></content>
        <author>
            <name>lrnzslrn83</name>
            <email>lrnzslrn83@noreply.github.com</email>
            <uri>https://github.com/lrnzslrn83</uri>
        </author>
        <published>2026-02-23T10:51:59.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nacho4412gg/nacho4412gg.github.io: ü¶ñ Explore DINOv3, a state-of-the-art backbone for computer vision models, now integrated with Hugging Face and PyTorch for enhanced performance and flexibility.]]></title>
        <id>https://github.com/Nacho4412gg/nacho4412gg.github.io</id>
        <link href="https://github.com/Nacho4412gg/nacho4412gg.github.io"/>
        <updated>2026-02-22T19:04:07.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/204909044?v=4" width="64" height="64" alt=""/><br/><div>ü¶ñ Explore DINOv3, a state-of-the-art backbone for computer vision models, now integrated with Hugging Face and PyTorch for enhanced performance and flexibility.</div>]]></content>
        <author>
            <name>Nacho4412gg</name>
            <email>Nacho4412gg@noreply.github.com</email>
            <uri>https://github.com/Nacho4412gg</uri>
        </author>
        <published>2026-01-11T18:30:14.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[JasonTzimas/DINOv3-powered-YOLOv11: An optimized Distillation pipeline for Knowledge-Transfer between DINOv3 and YOLOv11]]></title>
        <id>https://github.com/JasonTzimas/DINOv3-powered-YOLOv11</id>
        <link href="https://github.com/JasonTzimas/DINOv3-powered-YOLOv11"/>
        <updated>2026-02-22T11:19:19.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/76654609?v=4" width="64" height="64" alt=""/><br/><div>An optimized Distillation pipeline for Knowledge-Transfer between DINOv3 and YOLOv11</div>]]></content>
        <author>
            <name>JasonTzimas</name>
            <email>JasonTzimas@noreply.github.com</email>
            <uri>https://github.com/JasonTzimas</uri>
        </author>
        <published>2026-02-22T11:19:15.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[jaychempan/V2-SAM: [CVPR'26] Official Code for ‚ÄúV¬≤-SAM: Marrying SAM2 with Multi-Prompt Experts for Cross-View Object Correspondence‚Äù]]></title>
        <id>https://github.com/jaychempan/V2-SAM</id>
        <link href="https://github.com/jaychempan/V2-SAM"/>
        <updated>2026-02-23T13:05:34.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/74408955?u=7500f66b0d147f3e1a9b035dc5dcce7f30abeaae&v=4" width="64" height="64" alt=""/><br/><div>[CVPR'26] Official Code for ‚ÄúV¬≤-SAM: Marrying SAM2 with Multi-Prompt Experts for Cross-View Object Correspondence‚Äù</div>]]></content>
        <author>
            <name>jaychempan</name>
            <email>jaychempan@noreply.github.com</email>
            <uri>https://github.com/jaychempan</uri>
        </author>
        <published>2025-12-10T14:01:47.000Z</published>
    </entry>
</feed>