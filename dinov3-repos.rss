<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://cdekort.github.io/github-search-rss/dinov3-repos.rss</id>
    <title>DINOv3 Repositories</title>
    <updated>2025-12-11T17:07:01.955Z</updated>
    <generator>github-search-rss</generator>
    <link rel="alternate" href="https://cdekort.github.io/github-search-rss/dinov3-repos.rss"/>
    <subtitle>DINOv3 Repositories on GitHub</subtitle>
    <rights>github-search-rss</rights>
    <entry>
        <title type="html"><![CDATA[dlidgett/AD-DINOv3: üîç Enhance anomaly detection with AD-DINOv3, a framework adapting DINOv3 for zero-shot scenarios through advanced calibration techniques.]]></title>
        <id>https://github.com/dlidgett/AD-DINOv3</id>
        <link href="https://github.com/dlidgett/AD-DINOv3"/>
        <updated>2025-12-11T15:41:24.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/66205403?v=4" width="64" height="64" alt=""/><br/><div>üîç Enhance anomaly detection with AD-DINOv3, a framework adapting DINOv3 for zero-shot scenarios through advanced calibration techniques.</div>]]></content>
        <author>
            <name>dlidgett</name>
            <email>dlidgett@noreply.github.com</email>
            <uri>https://github.com/dlidgett</uri>
        </author>
        <published>2020-05-31T11:42:52.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[lightly-ai/lightly-train: All-in-one training for vision models (YOLO, ViTs, RT-DETR, DINOv3): pretraining, fine-tuning, distillation.]]></title>
        <id>https://github.com/lightly-ai/lightly-train</id>
        <link href="https://github.com/lightly-ai/lightly-train"/>
        <updated>2025-12-11T15:16:58.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/50146475?v=4" width="64" height="64" alt=""/><br/><div>All-in-one training for vision models (YOLO, ViTs, RT-DETR, DINOv3): pretraining, fine-tuning, distillation.</div>]]></content>
        <author>
            <name>lightly-ai</name>
            <email>lightly-ai@noreply.github.com</email>
            <uri>https://github.com/lightly-ai</uri>
        </author>
        <published>2025-04-10T08:23:51.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Wendy-xinn/dinov3]]></title>
        <id>https://github.com/Wendy-xinn/dinov3</id>
        <link href="https://github.com/Wendy-xinn/dinov3"/>
        <updated>2025-12-11T03:36:49.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/207971121?v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>Wendy-xinn</name>
            <email>Wendy-xinn@noreply.github.com</email>
            <uri>https://github.com/Wendy-xinn</uri>
        </author>
        <published>2025-12-11T03:36:07.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[avanishd-3/skin-lesion-classification: EfficientNet v2-M vs DINO v3-Base for Skin Lesion Classification]]></title>
        <id>https://github.com/avanishd-3/skin-lesion-classification</id>
        <link href="https://github.com/avanishd-3/skin-lesion-classification"/>
        <updated>2025-12-11T00:59:41.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/113077588?v=4" width="64" height="64" alt=""/><br/><div>EfficientNet v2-M vs DINO v3-Base for Skin Lesion Classification</div>]]></content>
        <author>
            <name>avanishd-3</name>
            <email>avanishd-3@noreply.github.com</email>
            <uri>https://github.com/avanishd-3</uri>
        </author>
        <published>2025-12-11T00:37:31.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[marjanstoimchev/DinoV3LightningTraining]]></title>
        <id>https://github.com/marjanstoimchev/DinoV3LightningTraining</id>
        <link href="https://github.com/marjanstoimchev/DinoV3LightningTraining"/>
        <updated>2025-12-10T13:16:32.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/62183782?u=b80fd2d98efc3e954b99b36f58bcee30fd8cf667&v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>marjanstoimchev</name>
            <email>marjanstoimchev@noreply.github.com</email>
            <uri>https://github.com/marjanstoimchev</uri>
        </author>
        <published>2025-09-07T08:24:08.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[hezhicheng2002/DINOv3-FD]]></title>
        <id>https://github.com/hezhicheng2002/DINOv3-FD</id>
        <link href="https://github.com/hezhicheng2002/DINOv3-FD"/>
        <updated>2025-12-10T10:51:48.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/106535937?u=a4f2824551815c2eb08c7bde38160fb65d4a6f9c&v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>hezhicheng2002</name>
            <email>hezhicheng2002@noreply.github.com</email>
            <uri>https://github.com/hezhicheng2002</uri>
        </author>
        <published>2025-11-29T12:33:45.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[K1947/AD-DINOv3: AD-DINOv3: Enhancing DINOv3 for Zero-Shot Anomaly Detection with Anomaly-Aware Calibration]]></title>
        <id>https://github.com/K1947/AD-DINOv3</id>
        <link href="https://github.com/K1947/AD-DINOv3"/>
        <updated>2025-12-10T05:44:38.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/182711040?v=4" width="64" height="64" alt=""/><br/><div>AD-DINOv3: Enhancing DINOv3 for Zero-Shot Anomaly Detection with Anomaly-Aware Calibration</div>]]></content>
        <author>
            <name>K1947</name>
            <email>K1947@noreply.github.com</email>
            <uri>https://github.com/K1947</uri>
        </author>
        <published>2025-11-13T05:06:12.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[jinjinran2001/dl_dinov3]]></title>
        <id>https://github.com/jinjinran2001/dl_dinov3</id>
        <link href="https://github.com/jinjinran2001/dl_dinov3"/>
        <updated>2025-12-09T23:38:19.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/129996835?v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>jinjinran2001</name>
            <email>jinjinran2001@noreply.github.com</email>
            <uri>https://github.com/jinjinran2001</uri>
        </author>
        <published>2025-12-09T23:31:49.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[bebemdjd/DINOv3-Retraining-Framework:  A self-supervised learning framework based on DINOv3 (Vision Transformer) for custom dataset retraining. This project implements training, evaluation, and visualization tools with flexible configuration options.]]></title>
        <id>https://github.com/bebemdjd/DINOv3-Retraining-Framework</id>
        <link href="https://github.com/bebemdjd/DINOv3-Retraining-Framework"/>
        <updated>2025-12-09T11:03:28.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/112637309?u=e665ef89d7c2ac53511cdd54918aa4fb7d0eb173&v=4" width="64" height="64" alt=""/><br/><div> A self-supervised learning framework based on DINOv3 (Vision Transformer) for custom dataset retraining. This project implements training, evaluation, and visualization tools with flexible configuration options.</div>]]></content>
        <author>
            <name>bebemdjd</name>
            <email>bebemdjd@noreply.github.com</email>
            <uri>https://github.com/bebemdjd</uri>
        </author>
        <published>2025-12-09T09:46:28.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[BeibeiIsFreshman/DINOv3_SAM: Knowledge Distillation from DINOv3-Guided SAM for Lightweight Underwater Salient Object Detection]]></title>
        <id>https://github.com/BeibeiIsFreshman/DINOv3_SAM</id>
        <link href="https://github.com/BeibeiIsFreshman/DINOv3_SAM"/>
        <updated>2025-12-09T06:59:25.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/146430099?v=4" width="64" height="64" alt=""/><br/><div>Knowledge Distillation from DINOv3-Guided SAM for Lightweight Underwater Salient Object Detection</div>]]></content>
        <author>
            <name>BeibeiIsFreshman</name>
            <email>BeibeiIsFreshman@noreply.github.com</email>
            <uri>https://github.com/BeibeiIsFreshman</uri>
        </author>
        <published>2025-12-09T06:49:32.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[ColdVI/Fish-Segmentation-DINOv3: DINOv3-based semantic segmentation pipeline for large-scale fish datasets. Includes data loading, preprocessing, model inference, training, evaluation, and advanced visualization of segmentation results.]]></title>
        <id>https://github.com/ColdVI/Fish-Segmentation-DINOv3</id>
        <link href="https://github.com/ColdVI/Fish-Segmentation-DINOv3"/>
        <updated>2025-12-08T20:52:36.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/126476389?u=be6e69e5a096dd1d251d599a168641d36edabda5&v=4" width="64" height="64" alt=""/><br/><div>DINOv3-based semantic segmentation pipeline for large-scale fish datasets. Includes data loading, preprocessing, model inference, training, evaluation, and advanced visualization of segmentation results.</div>]]></content>
        <author>
            <name>ColdVI</name>
            <email>ColdVI@noreply.github.com</email>
            <uri>https://github.com/ColdVI</uri>
        </author>
        <published>2025-12-04T09:40:40.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[chaejoon23/DINOv3-image-similarity-search-system-TEST]]></title>
        <id>https://github.com/chaejoon23/DINOv3-image-similarity-search-system-TEST</id>
        <link href="https://github.com/chaejoon23/DINOv3-image-similarity-search-system-TEST"/>
        <updated>2025-12-08T14:38:39.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/83930955?u=84eba9044744d0140f62e2b4909d7c51e1ad630a&v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>chaejoon23</name>
            <email>chaejoon23@noreply.github.com</email>
            <uri>https://github.com/chaejoon23</uri>
        </author>
        <published>2025-12-08T14:36:49.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[andykr1k/DinoV3Applied]]></title>
        <id>https://github.com/andykr1k/DinoV3Applied</id>
        <link href="https://github.com/andykr1k/DinoV3Applied"/>
        <updated>2025-12-08T07:30:10.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/69021102?u=7da65454f9bb80ea1ac18634f22dba9770912763&v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>andykr1k</name>
            <email>andykr1k@noreply.github.com</email>
            <uri>https://github.com/andykr1k</uri>
        </author>
        <published>2025-12-08T07:23:58.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[risebeforeshining/Dinov3-LMM: Dinov3-pretrained lmm based on LLaVA structure. The mlp]]></title>
        <id>https://github.com/risebeforeshining/Dinov3-LMM</id>
        <link href="https://github.com/risebeforeshining/Dinov3-LMM"/>
        <updated>2025-12-08T06:50:38.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/44262356?u=c11757ca9bc126d34c0e8254920cb76c444d565c&v=4" width="64" height="64" alt=""/><br/><div>Dinov3-pretrained lmm based on LLaVA structure. The mlp</div>]]></content>
        <author>
            <name>risebeforeshining</name>
            <email>risebeforeshining@noreply.github.com</email>
            <uri>https://github.com/risebeforeshining</uri>
        </author>
        <published>2025-12-08T06:37:59.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[tim-fan/festivity_maps: Mapping neighbourhood festivity levels with DINOv3]]></title>
        <id>https://github.com/tim-fan/festivity_maps</id>
        <link href="https://github.com/tim-fan/festivity_maps"/>
        <updated>2025-12-08T06:32:25.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/7835911?v=4" width="64" height="64" alt=""/><br/><div>Mapping neighbourhood festivity levels with DINOv3</div>]]></content>
        <author>
            <name>tim-fan</name>
            <email>tim-fan@noreply.github.com</email>
            <uri>https://github.com/tim-fan</uri>
        </author>
        <published>2025-11-24T04:06:04.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[CharlesChang012/3D-Semantic-Segmentation-Fusion: This repository implements a multi-modal 3D semantic segmentation and reconstruction system that fuses LiDAR point clouds and RGB images for autonomous scene understanding.]]></title>
        <id>https://github.com/CharlesChang012/3D-Semantic-Segmentation-Fusion</id>
        <link href="https://github.com/CharlesChang012/3D-Semantic-Segmentation-Fusion"/>
        <updated>2025-12-08T02:11:39.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/99932218?u=5e9953d299638b65e023c2c7a88050bfd030477b&v=4" width="64" height="64" alt=""/><br/><div>This repository implements a multi-modal 3D semantic segmentation and reconstruction system that fuses LiDAR point clouds and RGB images for autonomous scene understanding.</div>]]></content>
        <author>
            <name>CharlesChang012</name>
            <email>CharlesChang012@noreply.github.com</email>
            <uri>https://github.com/CharlesChang012</uri>
        </author>
        <published>2025-10-25T01:11:11.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Navifra-Bero/SAM3_DINOv3-Image-Matching]]></title>
        <id>https://github.com/Navifra-Bero/SAM3_DINOv3-Image-Matching</id>
        <link href="https://github.com/Navifra-Bero/SAM3_DINOv3-Image-Matching"/>
        <updated>2025-12-08T01:30:35.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/217902505?v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>Navifra-Bero</name>
            <email>Navifra-Bero@noreply.github.com</email>
            <uri>https://github.com/Navifra-Bero</uri>
        </author>
        <published>2025-12-08T01:30:31.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pratham-22/owlv2-dinov3-open-vocabulary-pipeline: Two-stage open-vocabulary vision pipeline combining OWLv2 detection with DINOv3 patch-level embeddings for zero-shot classification. Supports batched, GPU-accelerated inference, parallel object processing, cropped patch export, and detailed JSON + log outputs for research-grade analysis.]]></title>
        <id>https://github.com/Pratham-22/owlv2-dinov3-open-vocabulary-pipeline</id>
        <link href="https://github.com/Pratham-22/owlv2-dinov3-open-vocabulary-pipeline"/>
        <updated>2025-12-06T17:15:49.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/88884985?u=0d1cebf5947704141b9771b9d698f7cd0dcedd27&v=4" width="64" height="64" alt=""/><br/><div>Two-stage open-vocabulary vision pipeline combining OWLv2 detection with DINOv3 patch-level embeddings for zero-shot classification. Supports batched, GPU-accelerated inference, parallel object processing, cropped patch export, and detailed JSON + log outputs for research-grade analysis.</div>]]></content>
        <author>
            <name>Pratham-22</name>
            <email>Pratham-22@noreply.github.com</email>
            <uri>https://github.com/Pratham-22</uri>
        </author>
        <published>2025-12-06T04:04:28.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[devMuniz02/UDEM-CXR-Reporting-Thesis-2025: Multimodal chest X-ray diagnosis + AI report generation using DINOv3 and a GPT-based model with modified transformer attention. UDEM thesis project.]]></title>
        <id>https://github.com/devMuniz02/UDEM-CXR-Reporting-Thesis-2025</id>
        <link href="https://github.com/devMuniz02/UDEM-CXR-Reporting-Thesis-2025"/>
        <updated>2025-12-06T16:28:35.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/118771029?u=955fe98be3158a661f72095cd7d65fa8bd4b1282&v=4" width="64" height="64" alt=""/><br/><div>Multimodal chest X-ray diagnosis + AI report generation using DINOv3 and a GPT-based model with modified transformer attention. UDEM thesis project.</div>]]></content>
        <author>
            <name>devMuniz02</name>
            <email>devMuniz02@noreply.github.com</email>
            <uri>https://github.com/devMuniz02</uri>
        </author>
        <published>2025-06-06T16:10:17.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[hyuchi123/CVPDL_IP_CLIP_DINOv3: Á∑¥ÁøíÂæ©Âàª‰øÆÊîπhttps://github.com/LyWang12/IP-CLIP/tree/main]]></title>
        <id>https://github.com/hyuchi123/CVPDL_IP_CLIP_DINOv3</id>
        <link href="https://github.com/hyuchi123/CVPDL_IP_CLIP_DINOv3"/>
        <updated>2025-12-06T10:47:52.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/153170507?v=4" width="64" height="64" alt=""/><br/><div>Á∑¥ÁøíÂæ©Âàª‰øÆÊîπ<a href="https://github.com/LyWang12/IP-CLIP/tree/main" class="Link--inTextBlock">https://github.com/LyWang12/IP-CLIP/tree/main</a></div>]]></content>
        <author>
            <name>hyuchi123</name>
            <email>hyuchi123@noreply.github.com</email>
            <uri>https://github.com/hyuchi123</uri>
        </author>
        <published>2025-12-06T07:10:20.000Z</published>
    </entry>
</feed>