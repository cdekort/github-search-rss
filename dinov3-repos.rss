<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://cdekort.github.io/github-search-rss/dinov3-repos.rss</id>
    <title>DINOv3 Repositories</title>
    <updated>2026-02-10T00:39:11.788Z</updated>
    <generator>github-search-rss</generator>
    <link rel="alternate" href="https://cdekort.github.io/github-search-rss/dinov3-repos.rss"/>
    <subtitle>DINOv3 Repositories on GitHub</subtitle>
    <rights>github-search-rss</rights>
    <entry>
        <title type="html"><![CDATA[dlidgett/AD-DINOv3: üîç Enhance anomaly detection with AD-DINOv3, a framework adapting DINOv3 for zero-shot scenarios through advanced calibration techniques.]]></title>
        <id>https://github.com/dlidgett/AD-DINOv3</id>
        <link href="https://github.com/dlidgett/AD-DINOv3"/>
        <updated>2026-02-10T00:36:19.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/66205403?v=4" width="64" height="64" alt=""/><br/><div>üîç Enhance anomaly detection with AD-DINOv3, a framework adapting DINOv3 for zero-shot scenarios through advanced calibration techniques.</div>]]></content>
        <author>
            <name>dlidgett</name>
            <email>dlidgett@noreply.github.com</email>
            <uri>https://github.com/dlidgett</uri>
        </author>
        <published>2020-05-31T11:42:52.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nacho4412gg/dinov3]]></title>
        <id>https://github.com/Nacho4412gg/dinov3</id>
        <link href="https://github.com/Nacho4412gg/dinov3"/>
        <updated>2026-02-09T22:47:13.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/204909044?v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>Nacho4412gg</name>
            <email>Nacho4412gg@noreply.github.com</email>
            <uri>https://github.com/Nacho4412gg</uri>
        </author>
        <published>2026-01-11T18:24:22.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[enot-style/imbeddings: A minimal FastAPI service for generating image embeddings using Hugging Face Vision Transformer models.]]></title>
        <id>https://github.com/enot-style/imbeddings</id>
        <link href="https://github.com/enot-style/imbeddings"/>
        <updated>2026-02-09T20:11:47.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/260076530?v=4" width="64" height="64" alt=""/><br/><div>A minimal FastAPI service for generating image embeddings using Hugging Face Vision Transformer models.</div>]]></content>
        <author>
            <name>enot-style</name>
            <email>enot-style@noreply.github.com</email>
            <uri>https://github.com/enot-style</uri>
        </author>
        <published>2026-01-08T21:52:55.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[GIS-Remote-Sensing-Goettingen/Dinov3-LWF-Segmentation]]></title>
        <id>https://github.com/GIS-Remote-Sensing-Goettingen/Dinov3-LWF-Segmentation</id>
        <link href="https://github.com/GIS-Remote-Sensing-Goettingen/Dinov3-LWF-Segmentation"/>
        <updated>2026-02-09T17:40:59.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/231213492?v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>GIS-Remote-Sensing-Goettingen</name>
            <email>GIS-Remote-Sensing-Goettingen@noreply.github.com</email>
            <uri>https://github.com/GIS-Remote-Sensing-Goettingen</uri>
        </author>
        <published>2026-02-02T13:58:10.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Indeera01/FYP-DINOv3-Indeera]]></title>
        <id>https://github.com/Indeera01/FYP-DINOv3-Indeera</id>
        <link href="https://github.com/Indeera01/FYP-DINOv3-Indeera"/>
        <updated>2026-02-09T13:22:50.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/129371871?v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>Indeera01</name>
            <email>Indeera01@noreply.github.com</email>
            <uri>https://github.com/Indeera01</uri>
        </author>
        <published>2026-01-03T04:36:31.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[lightly-ai/lightly-train: All-in-one training for vision models (YOLO, ViTs, RT-DETR, DINOv3): pretraining, fine-tuning, distillation.]]></title>
        <id>https://github.com/lightly-ai/lightly-train</id>
        <link href="https://github.com/lightly-ai/lightly-train"/>
        <updated>2026-02-09T20:56:33.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/50146475?v=4" width="64" height="64" alt=""/><br/><div>All-in-one training for vision models (YOLO, ViTs, RT-DETR, DINOv3): pretraining, fine-tuning, distillation.</div>]]></content>
        <author>
            <name>lightly-ai</name>
            <email>lightly-ai@noreply.github.com</email>
            <uri>https://github.com/lightly-ai</uri>
        </author>
        <published>2025-04-10T08:23:51.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[SheerXu/DINOv3_with_variety]]></title>
        <id>https://github.com/SheerXu/DINOv3_with_variety</id>
        <link href="https://github.com/SheerXu/DINOv3_with_variety"/>
        <updated>2026-02-09T10:08:14.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/59718234?u=2636b457438baf8f5e92efb7c4c2f2506ff00ffe&v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>SheerXu</name>
            <email>SheerXu@noreply.github.com</email>
            <uri>https://github.com/SheerXu</uri>
        </author>
        <published>2026-02-09T10:01:41.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[RobvanGastel/removing-pos-vit-bias: Using RASA post-training to remove positional bias from pretrained encoders like DINOv3]]></title>
        <id>https://github.com/RobvanGastel/removing-pos-vit-bias</id>
        <link href="https://github.com/RobvanGastel/removing-pos-vit-bias"/>
        <updated>2026-02-08T21:00:20.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/10989988?u=502b123d5cea37ca569f76261e89c43540380cf8&v=4" width="64" height="64" alt=""/><br/><div>Using RASA post-training to remove positional bias from pretrained encoders like DINOv3</div>]]></content>
        <author>
            <name>RobvanGastel</name>
            <email>RobvanGastel@noreply.github.com</email>
            <uri>https://github.com/RobvanGastel</uri>
        </author>
        <published>2025-07-25T13:56:55.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[zgcr/SimpleAICV_pytorch_training_examples: SimpleAICV:pytorch training examples.]]></title>
        <id>https://github.com/zgcr/SimpleAICV_pytorch_training_examples</id>
        <link href="https://github.com/zgcr/SimpleAICV_pytorch_training_examples"/>
        <updated>2026-02-09T02:00:01.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/19390485?u=d9f77e6cad56ea1c0c19ea2852b7833c76d2cf4a&v=4" width="64" height="64" alt=""/><br/><div>SimpleAICV:pytorch training examples.</div>]]></content>
        <author>
            <name>zgcr</name>
            <email>zgcr@noreply.github.com</email>
            <uri>https://github.com/zgcr</uri>
        </author>
        <published>2020-05-31T05:37:26.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[StephenQSstarThomas/dinov3-finetune]]></title>
        <id>https://github.com/StephenQSstarThomas/dinov3-finetune</id>
        <link href="https://github.com/StephenQSstarThomas/dinov3-finetune"/>
        <updated>2026-02-08T08:50:10.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/112707323?u=7c4b10d65c66f0e35dd75808a0fffb3f6d8f134f&v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>StephenQSstarThomas</name>
            <email>StephenQSstarThomas@noreply.github.com</email>
            <uri>https://github.com/StephenQSstarThomas</uri>
        </author>
        <published>2025-11-24T19:08:45.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[PhilaMaster/semantic_correspondence: This project evaluates and fine-tunes models like DINOv2, DINOv3, and Segment Anything Model (SAM) for dense matching tasks, enabling precise keypoint matching across semantically similar images.]]></title>
        <id>https://github.com/PhilaMaster/semantic_correspondence</id>
        <link href="https://github.com/PhilaMaster/semantic_correspondence"/>
        <updated>2026-02-07T16:23:04.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/77679627?v=4" width="64" height="64" alt=""/><br/><div>This project evaluates and fine-tunes models like DINOv2, DINOv3, and Segment Anything Model (SAM) for dense matching tasks, enabling precise keypoint matching across semantically similar images.</div>]]></content>
        <author>
            <name>PhilaMaster</name>
            <email>PhilaMaster@noreply.github.com</email>
            <uri>https://github.com/PhilaMaster</uri>
        </author>
        <published>2025-12-10T18:01:11.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[talhabw/autoseg: an annotation tool for segmentation models, with SAM3 integration and automatic propagation using image encoder models (DINOv3 and Pixio)]]></title>
        <id>https://github.com/talhabw/autoseg</id>
        <link href="https://github.com/talhabw/autoseg"/>
        <updated>2026-02-07T14:22:54.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/56639619?u=1a98caa2017443e235e7b84fc18a7182ec8a8a18&v=4" width="64" height="64" alt=""/><br/><div>an annotation tool for segmentation models, with SAM3 integration and automatic propagation using image encoder models (DINOv3 and Pixio)</div>]]></content>
        <author>
            <name>talhabw</name>
            <email>talhabw@noreply.github.com</email>
            <uri>https://github.com/talhabw</uri>
        </author>
        <published>2025-12-27T19:05:03.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[longxiang-ai/TransNormal: Official implementation of "TransNormal: Dense Visual Semantics for Diffusion-based Transparent Object Normal Estimation" (arXiv 2026). Single-step diffusion model for accurate surface normal prediction of transparent objects.]]></title>
        <id>https://github.com/longxiang-ai/TransNormal</id>
        <link href="https://github.com/longxiang-ai/TransNormal"/>
        <updated>2026-02-09T12:48:22.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/68198130?u=6a9b87af1d8b6a5686fe1af7451d13c7cb0f4d13&v=4" width="64" height="64" alt=""/><br/><div>Official implementation of "TransNormal: Dense Visual Semantics for Diffusion-based Transparent Object Normal Estimation" (arXiv 2026). Single-step diffusion model for accurate surface normal prediction of transparent objects.</div>]]></content>
        <author>
            <name>longxiang-ai</name>
            <email>longxiang-ai@noreply.github.com</email>
            <uri>https://github.com/longxiang-ai</uri>
        </author>
        <published>2026-01-30T05:10:23.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[quanpham3105/DINOv3-Tracking-Research-CPX-Lab-]]></title>
        <id>https://github.com/quanpham3105/DINOv3-Tracking-Research-CPX-Lab-</id>
        <link href="https://github.com/quanpham3105/DINOv3-Tracking-Research-CPX-Lab-"/>
        <updated>2026-02-06T00:31:53.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/61221633?v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>quanpham3105</name>
            <email>quanpham3105@noreply.github.com</email>
            <uri>https://github.com/quanpham3105</uri>
        </author>
        <published>2025-10-29T21:11:13.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[LukaDarsalia/colormnet_dinov3]]></title>
        <id>https://github.com/LukaDarsalia/colormnet_dinov3</id>
        <link href="https://github.com/LukaDarsalia/colormnet_dinov3"/>
        <updated>2026-02-05T23:47:05.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/29729836?u=d5b98a781f2e3e93ae1b3b9229177256600b097a&v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>LukaDarsalia</name>
            <email>LukaDarsalia@noreply.github.com</email>
            <uri>https://github.com/LukaDarsalia</uri>
        </author>
        <published>2026-02-03T17:34:48.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Raessan/dinov3_deepstream: DeepStream integration of Meta‚Äôs DINOv3 backbone with lightweight heads for vision tasks. ]]></title>
        <id>https://github.com/Raessan/dinov3_deepstream</id>
        <link href="https://github.com/Raessan/dinov3_deepstream"/>
        <updated>2026-02-09T15:23:47.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/81997218?u=5b16f2f94a92448943c16f5a3eda9597dff2f44a&v=4" width="64" height="64" alt=""/><br/><div>DeepStream integration of Meta‚Äôs DINOv3 backbone with lightweight heads for vision tasks. </div>]]></content>
        <author>
            <name>Raessan</name>
            <email>Raessan@noreply.github.com</email>
            <uri>https://github.com/Raessan</uri>
        </author>
        <published>2026-01-02T20:12:47.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[GIS-Remote-Sensing-Goettingen/dinov3-LWF-Segmentation-erosion]]></title>
        <id>https://github.com/GIS-Remote-Sensing-Goettingen/dinov3-LWF-Segmentation-erosion</id>
        <link href="https://github.com/GIS-Remote-Sensing-Goettingen/dinov3-LWF-Segmentation-erosion"/>
        <updated>2026-02-05T18:05:23.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/231213492?v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>GIS-Remote-Sensing-Goettingen</name>
            <email>GIS-Remote-Sensing-Goettingen@noreply.github.com</email>
            <uri>https://github.com/GIS-Remote-Sensing-Goettingen</uri>
        </author>
        <published>2026-01-26T13:43:19.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[johnamit/motoreid: A deep learning pipeline for MotoGP team detection, tracking, and re-identification from race broadcast footage. This system combines YOLOv8 for robust object detection with DINOv3 (Vision Transformer) embeddings for semantic team classification.]]></title>
        <id>https://github.com/johnamit/motoreid</id>
        <link href="https://github.com/johnamit/motoreid"/>
        <updated>2026-02-05T15:09:02.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/75620312?u=8806c49054eb4620ae51aa548c5f08997486b21e&v=4" width="64" height="64" alt=""/><br/><div>A deep learning pipeline for MotoGP team detection, tracking, and re-identification from race broadcast footage. This system combines YOLOv8 for robust object detection with DINOv3 (Vision Transformer) embeddings for semantic team classification.</div>]]></content>
        <author>
            <name>johnamit</name>
            <email>johnamit@noreply.github.com</email>
            <uri>https://github.com/johnamit</uri>
        </author>
        <published>2026-01-14T18:42:24.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[RomanRes/CSIRO-Biomass-Prediction-using-DINOv3: The project focuses on modern computer vision techniques and demonstrates how large self-supervised vision transformers can be adapted efficiently for regression tasks using parameter-efficient fine-tuning.]]></title>
        <id>https://github.com/RomanRes/CSIRO-Biomass-Prediction-using-DINOv3</id>
        <link href="https://github.com/RomanRes/CSIRO-Biomass-Prediction-using-DINOv3"/>
        <updated>2026-02-05T13:17:20.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/62020123?u=46315ce64061756a2b722c9dc3857a3ff440baae&v=4" width="64" height="64" alt=""/><br/><div>The project focuses on modern computer vision techniques and demonstrates how large self-supervised vision transformers can be adapted efficiently for regression tasks using parameter-efficient fine-tuning.</div>]]></content>
        <author>
            <name>RomanRes</name>
            <email>RomanRes@noreply.github.com</email>
            <uri>https://github.com/RomanRes</uri>
        </author>
        <published>2026-02-02T19:49:23.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[jayd972/Multi-Agent-dinov3-explainable-tumor-detection-framework]]></title>
        <id>https://github.com/jayd972/Multi-Agent-dinov3-explainable-tumor-detection-framework</id>
        <link href="https://github.com/jayd972/Multi-Agent-dinov3-explainable-tumor-detection-framework"/>
        <updated>2026-02-05T11:33:04.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/75724261?u=ec9417a3cccd67a77f38c9ae073a07dd8af99e9e&v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>jayd972</name>
            <email>jayd972@noreply.github.com</email>
            <uri>https://github.com/jayd972</uri>
        </author>
        <published>2026-02-05T11:01:15.000Z</published>
    </entry>
</feed>