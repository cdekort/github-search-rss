<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://cdekort.github.io/github-search-rss/dinov3-repos.rss</id>
    <title>DINOv3 Repositories</title>
    <updated>2026-02-26T00:30:41.736Z</updated>
    <generator>github-search-rss</generator>
    <link rel="alternate" href="https://cdekort.github.io/github-search-rss/dinov3-repos.rss"/>
    <subtitle>DINOv3 Repositories on GitHub</subtitle>
    <rights>github-search-rss</rights>
    <entry>
        <title type="html"><![CDATA[Abigail-amk/AI-training: ü§ñ Enhance programming education by fine-tuning the Phi-3 Mini model to deliver well-structured, documented code responses, ensuring best practices in coding.]]></title>
        <id>https://github.com/Abigail-amk/AI-training</id>
        <link href="https://github.com/Abigail-amk/AI-training"/>
        <updated>2026-02-25T23:58:23.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/204875701?v=4" width="64" height="64" alt=""/><br/><div>ü§ñ Enhance programming education by fine-tuning the Phi-3 Mini model to deliver well-structured, documented code responses, ensuring best practices in coding.</div>]]></content>
        <author>
            <name>Abigail-amk</name>
            <email>Abigail-amk@noreply.github.com</email>
            <uri>https://github.com/Abigail-amk</uri>
        </author>
        <published>2026-02-15T00:26:11.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nacho4412gg/dinov3]]></title>
        <id>https://github.com/Nacho4412gg/dinov3</id>
        <link href="https://github.com/Nacho4412gg/dinov3"/>
        <updated>2026-02-25T23:31:04.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/204909044?v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>Nacho4412gg</name>
            <email>Nacho4412gg@noreply.github.com</email>
            <uri>https://github.com/Nacho4412gg</uri>
        </author>
        <published>2026-01-11T18:24:22.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[dlidgett/AD-DINOv3: üîç Enhance anomaly detection with AD-DINOv3, a framework adapting DINOv3 for zero-shot scenarios through advanced calibration techniques.]]></title>
        <id>https://github.com/dlidgett/AD-DINOv3</id>
        <link href="https://github.com/dlidgett/AD-DINOv3"/>
        <updated>2026-02-25T22:18:51.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/66205403?v=4" width="64" height="64" alt=""/><br/><div>üîç Enhance anomaly detection with AD-DINOv3, a framework adapting DINOv3 for zero-shot scenarios through advanced calibration techniques.</div>]]></content>
        <author>
            <name>dlidgett</name>
            <email>dlidgett@noreply.github.com</email>
            <uri>https://github.com/dlidgett</uri>
        </author>
        <published>2020-05-31T11:42:52.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[BeibeiIsFreshman/DINOv3_SAM: Knowledge Distillation from DINOv3-Guided SAM for Lightweight Underwater Salient Object Detection]]></title>
        <id>https://github.com/BeibeiIsFreshman/DINOv3_SAM</id>
        <link href="https://github.com/BeibeiIsFreshman/DINOv3_SAM"/>
        <updated>2026-02-25T18:25:52.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/146430099?v=4" width="64" height="64" alt=""/><br/><div>Knowledge Distillation from DINOv3-Guided SAM for Lightweight Underwater Salient Object Detection</div>]]></content>
        <author>
            <name>BeibeiIsFreshman</name>
            <email>BeibeiIsFreshman@noreply.github.com</email>
            <uri>https://github.com/BeibeiIsFreshman</uri>
        </author>
        <published>2025-12-09T06:49:32.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[worship93keypad/dinov3]]></title>
        <id>https://github.com/worship93keypad/dinov3</id>
        <link href="https://github.com/worship93keypad/dinov3"/>
        <updated>2026-02-25T14:05:10.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/259578465?v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>worship93keypad</name>
            <email>worship93keypad@noreply.github.com</email>
            <uri>https://github.com/worship93keypad</uri>
        </author>
        <published>2026-02-25T14:03:16.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[gaiadifilippo/Anatomically-Relevant-Frame-Selection-in-Laryngeal-Endoscopy: This repository contains code for classifying laryngeal endoscopic frames as anatomically relevant or not using DINOv3 embeddings and a trainable MLP. Includes interactive Jupyter widgets for active learning annotation to finetune the model to new dataset]]></title>
        <id>https://github.com/gaiadifilippo/Anatomically-Relevant-Frame-Selection-in-Laryngeal-Endoscopy</id>
        <link href="https://github.com/gaiadifilippo/Anatomically-Relevant-Frame-Selection-in-Laryngeal-Endoscopy"/>
        <updated>2026-02-25T13:28:50.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/215035633?v=4" width="64" height="64" alt=""/><br/><div>This repository contains code for classifying laryngeal endoscopic frames as anatomically relevant or not using DINOv3 embeddings and a trainable MLP. Includes interactive Jupyter widgets for active learning annotation to finetune the model to new dataset</div>]]></content>
        <author>
            <name>gaiadifilippo</name>
            <email>gaiadifilippo@noreply.github.com</email>
            <uri>https://github.com/gaiadifilippo</uri>
        </author>
        <published>2026-02-25T11:34:01.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Killuazyt/ChangVitDinov3: dinoV3  16ÁöÑÈÄÇÈÖç]]></title>
        <id>https://github.com/Killuazyt/ChangVitDinov3</id>
        <link href="https://github.com/Killuazyt/ChangVitDinov3"/>
        <updated>2026-02-25T12:34:56.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/67639242?u=dbeef5de4d3e32ecc3c786929417e21429b2c649&v=4" width="64" height="64" alt=""/><br/><div>dinoV3  16ÁöÑÈÄÇÈÖç</div>]]></content>
        <author>
            <name>Killuazyt</name>
            <email>Killuazyt@noreply.github.com</email>
            <uri>https://github.com/Killuazyt</uri>
        </author>
        <published>2026-02-25T12:05:34.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Thanghuynh2808/Retail-Insight-Pipeline: Automated Planogram Compliance system for retail shelves. Features: Panorama Stitching, Zero-shot SKU Detection (YOLO, DINOv3, LightGlue), and LLM-powered rule validation. Optimized for large-scale grocery shelf analysis in Vietnam.]]></title>
        <id>https://github.com/Thanghuynh2808/Retail-Insight-Pipeline</id>
        <link href="https://github.com/Thanghuynh2808/Retail-Insight-Pipeline"/>
        <updated>2026-02-25T08:01:54.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/156525690?u=859091d4e8fe94e40ba8c4ba1324563f3228fda3&v=4" width="64" height="64" alt=""/><br/><div>Automated Planogram Compliance system for retail shelves. Features: Panorama Stitching, Zero-shot SKU Detection (YOLO, DINOv3, LightGlue), and LLM-powered rule validation. Optimized for large-scale grocery shelf analysis in Vietnam.</div>]]></content>
        <author>
            <name>Thanghuynh2808</name>
            <email>Thanghuynh2808@noreply.github.com</email>
            <uri>https://github.com/Thanghuynh2808</uri>
        </author>
        <published>2026-02-03T02:40:51.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[pierrelgol/tea-ai: DinoV3-Yolo26-Pipeline]]></title>
        <id>https://github.com/pierrelgol/tea-ai</id>
        <link href="https://github.com/pierrelgol/tea-ai"/>
        <updated>2026-02-24T23:30:25.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/119697612?u=37a68a08bbf84ef9c713ac3f5ae7f32998c2e54e&v=4" width="64" height="64" alt=""/><br/><div>DinoV3-Yolo26-Pipeline</div>]]></content>
        <author>
            <name>pierrelgol</name>
            <email>pierrelgol@noreply.github.com</email>
            <uri>https://github.com/pierrelgol</uri>
        </author>
        <published>2026-02-22T10:58:01.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[violayhho/DinoX-Ray: Chest X-Ray perception pipeline using DINOv3. Demonstrates lightweight decoders with frozen foundation backbones for both image classification (COVID vs. Healthy) and semantic segmentation (Lung Masking) in PyTorch.]]></title>
        <id>https://github.com/violayhho/DinoX-Ray</id>
        <link href="https://github.com/violayhho/DinoX-Ray"/>
        <updated>2026-02-24T20:15:15.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/143129517?u=08c01ddda9b18b64df039f0ac35a626c7a65c38d&v=4" width="64" height="64" alt=""/><br/><div>Chest X-Ray perception pipeline using DINOv3. Demonstrates lightweight decoders with frozen foundation backbones for both image classification (COVID vs. Healthy) and semantic segmentation (Lung Masking) in PyTorch.</div>]]></content>
        <author>
            <name>violayhho</name>
            <email>violayhho@noreply.github.com</email>
            <uri>https://github.com/violayhho</uri>
        </author>
        <published>2026-02-24T20:08:38.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[lightly-ai/lightly-train: All-in-one training for vision models (YOLO, ViTs, RT-DETR, DINOv3): pretraining, fine-tuning, distillation.]]></title>
        <id>https://github.com/lightly-ai/lightly-train</id>
        <link href="https://github.com/lightly-ai/lightly-train"/>
        <updated>2026-02-25T09:36:27.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/50146475?v=4" width="64" height="64" alt=""/><br/><div>All-in-one training for vision models (YOLO, ViTs, RT-DETR, DINOv3): pretraining, fine-tuning, distillation.</div>]]></content>
        <author>
            <name>lightly-ai</name>
            <email>lightly-ai@noreply.github.com</email>
            <uri>https://github.com/lightly-ai</uri>
        </author>
        <published>2025-04-10T08:23:51.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[jseobyun/FaceDepth: DINOv3 based head depth estimation]]></title>
        <id>https://github.com/jseobyun/FaceDepth</id>
        <link href="https://github.com/jseobyun/FaceDepth"/>
        <updated>2026-02-24T08:52:16.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/53433086?u=165b43703aaa3163f65d4093a90f6ac2ce9473f1&v=4" width="64" height="64" alt=""/><br/><div>DINOv3 based head depth estimation</div>]]></content>
        <author>
            <name>jseobyun</name>
            <email>jseobyun@noreply.github.com</email>
            <uri>https://github.com/jseobyun</uri>
        </author>
        <published>2025-09-15T09:13:54.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[jseobyun/FaceParsing: DINOv3 based face parsing network]]></title>
        <id>https://github.com/jseobyun/FaceParsing</id>
        <link href="https://github.com/jseobyun/FaceParsing"/>
        <updated>2026-02-24T07:20:19.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/53433086?u=165b43703aaa3163f65d4093a90f6ac2ce9473f1&v=4" width="64" height="64" alt=""/><br/><div>DINOv3 based face parsing network</div>]]></content>
        <author>
            <name>jseobyun</name>
            <email>jseobyun@noreply.github.com</email>
            <uri>https://github.com/jseobyun</uri>
        </author>
        <published>2025-09-04T02:10:31.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[lrnzslrn83/Few-Shot-Classification-on-LIVECell-using-DINOv3-Embeddings: Questo progetto implementa un framework di few-shot learning per la classificazione di immagini cellulari del dataset LIVECell utilizzando embedding estratti da DINOv3, un Vision Transformer pre-addestrato in modalit√† self-supervised.]]></title>
        <id>https://github.com/lrnzslrn83/Few-Shot-Classification-on-LIVECell-using-DINOv3-Embeddings</id>
        <link href="https://github.com/lrnzslrn83/Few-Shot-Classification-on-LIVECell-using-DINOv3-Embeddings"/>
        <updated>2026-02-23T11:03:36.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/200913309?v=4" width="64" height="64" alt=""/><br/><div>Questo progetto implementa un framework di few-shot learning per la classificazione di immagini cellulari del dataset LIVECell utilizzando embedding estratti da DINOv3, un Vision Transformer pre-addestrato in modalit√† self-supervised.</div>]]></content>
        <author>
            <name>lrnzslrn83</name>
            <email>lrnzslrn83@noreply.github.com</email>
            <uri>https://github.com/lrnzslrn83</uri>
        </author>
        <published>2026-02-23T10:51:59.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nacho4412gg/nacho4412gg.github.io: ü¶ñ Explore DINOv3, a state-of-the-art backbone for computer vision models, now integrated with Hugging Face and PyTorch for enhanced performance and flexibility.]]></title>
        <id>https://github.com/Nacho4412gg/nacho4412gg.github.io</id>
        <link href="https://github.com/Nacho4412gg/nacho4412gg.github.io"/>
        <updated>2026-02-22T19:04:07.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/204909044?v=4" width="64" height="64" alt=""/><br/><div>ü¶ñ Explore DINOv3, a state-of-the-art backbone for computer vision models, now integrated with Hugging Face and PyTorch for enhanced performance and flexibility.</div>]]></content>
        <author>
            <name>Nacho4412gg</name>
            <email>Nacho4412gg@noreply.github.com</email>
            <uri>https://github.com/Nacho4412gg</uri>
        </author>
        <published>2026-01-11T18:30:14.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[JasonTzimas/DINOv3-powered-YOLOv11: An optimized Distillation pipeline for Knowledge-Transfer between DINOv3 and YOLOv11]]></title>
        <id>https://github.com/JasonTzimas/DINOv3-powered-YOLOv11</id>
        <link href="https://github.com/JasonTzimas/DINOv3-powered-YOLOv11"/>
        <updated>2026-02-22T11:19:19.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/76654609?v=4" width="64" height="64" alt=""/><br/><div>An optimized Distillation pipeline for Knowledge-Transfer between DINOv3 and YOLOv11</div>]]></content>
        <author>
            <name>JasonTzimas</name>
            <email>JasonTzimas@noreply.github.com</email>
            <uri>https://github.com/JasonTzimas</uri>
        </author>
        <published>2026-02-22T11:19:15.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[jaychempan/V2-SAM: [CVPR'26] Official Code for ‚ÄúV¬≤-SAM: Marrying SAM2 with Multi-Prompt Experts for Cross-View Object Correspondence‚Äù]]></title>
        <id>https://github.com/jaychempan/V2-SAM</id>
        <link href="https://github.com/jaychempan/V2-SAM"/>
        <updated>2026-02-23T13:05:34.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/74408955?u=7500f66b0d147f3e1a9b035dc5dcce7f30abeaae&v=4" width="64" height="64" alt=""/><br/><div>[CVPR'26] Official Code for ‚ÄúV¬≤-SAM: Marrying SAM2 with Multi-Prompt Experts for Cross-View Object Correspondence‚Äù</div>]]></content>
        <author>
            <name>jaychempan</name>
            <email>jaychempan@noreply.github.com</email>
            <uri>https://github.com/jaychempan</uri>
        </author>
        <published>2025-12-10T14:01:47.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[ArtemVerbov/Dinov3-For-Semantic-Segmentation: Dinov3 backbone adopted for semantic segmentation.]]></title>
        <id>https://github.com/ArtemVerbov/Dinov3-For-Semantic-Segmentation</id>
        <link href="https://github.com/ArtemVerbov/Dinov3-For-Semantic-Segmentation"/>
        <updated>2026-02-21T14:12:59.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/59263685?u=644171ead2758667b101b888269925d338b05ff4&v=4" width="64" height="64" alt=""/><br/><div>Dinov3 backbone adopted for semantic segmentation.</div>]]></content>
        <author>
            <name>ArtemVerbov</name>
            <email>ArtemVerbov@noreply.github.com</email>
            <uri>https://github.com/ArtemVerbov</uri>
        </author>
        <published>2026-01-25T07:01:47.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[JordiCan/galaxy_image_classifier: A deep learning pipeline for classifying galaxy morphologies from the Galaxy Zoo 2 dataset. It leverages the Hugging Face ecosystem to fine-tune state-of-the-art vision models using Parameter-Efficient Fine-Tuning (PEFT) techniques.]]></title>
        <id>https://github.com/JordiCan/galaxy_image_classifier</id>
        <link href="https://github.com/JordiCan/galaxy_image_classifier"/>
        <updated>2026-02-21T11:49:06.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/90319800?u=3c3ff160ac34fc527751da1e443dc3c83e3c0a31&v=4" width="64" height="64" alt=""/><br/><div>A deep learning pipeline for classifying galaxy morphologies from the Galaxy Zoo 2 dataset. It leverages the Hugging Face ecosystem to fine-tune state-of-the-art vision models using Parameter-Efficient Fine-Tuning (PEFT) techniques.</div>]]></content>
        <author>
            <name>JordiCan</name>
            <email>JordiCan@noreply.github.com</email>
            <uri>https://github.com/JordiCan</uri>
        </author>
        <published>2025-09-27T12:26:13.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[enot-style/imbeddings: A minimal FastAPI service for generating image embeddings using Hugging Face Vision Transformer models.]]></title>
        <id>https://github.com/enot-style/imbeddings</id>
        <link href="https://github.com/enot-style/imbeddings"/>
        <updated>2026-02-20T06:46:07.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/260076530?v=4" width="64" height="64" alt=""/><br/><div>A minimal FastAPI service for generating image embeddings using Hugging Face Vision Transformer models.</div>]]></content>
        <author>
            <name>enot-style</name>
            <email>enot-style@noreply.github.com</email>
            <uri>https://github.com/enot-style</uri>
        </author>
        <published>2026-01-08T21:52:55.000Z</published>
    </entry>
</feed>