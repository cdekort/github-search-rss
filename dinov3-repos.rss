<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://cdekort.github.io/github-search-rss/dinov3-repos.rss</id>
    <title>DINOv3 Repositories</title>
    <updated>2025-12-08T14:03:39.214Z</updated>
    <generator>github-search-rss</generator>
    <link rel="alternate" href="https://cdekort.github.io/github-search-rss/dinov3-repos.rss"/>
    <subtitle>DINOv3 Repositories on GitHub</subtitle>
    <rights>github-search-rss</rights>
    <entry>
        <title type="html"><![CDATA[dlidgett/AD-DINOv3: üîç Enhance anomaly detection with AD-DINOv3, a framework adapting DINOv3 for zero-shot scenarios through advanced calibration techniques.]]></title>
        <id>https://github.com/dlidgett/AD-DINOv3</id>
        <link href="https://github.com/dlidgett/AD-DINOv3"/>
        <updated>2025-12-08T11:46:23.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/66205403?v=4" width="64" height="64" alt=""/><br/><div>üîç Enhance anomaly detection with AD-DINOv3, a framework adapting DINOv3 for zero-shot scenarios through advanced calibration techniques.</div>]]></content>
        <author>
            <name>dlidgett</name>
            <email>dlidgett@noreply.github.com</email>
            <uri>https://github.com/dlidgett</uri>
        </author>
        <published>2020-05-31T11:42:52.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[lightly-ai/lightly-train: All-in-one training for vision models (YOLO, ViTs, RT-DETR, DINOv3): pretraining, fine-tuning, distillation.]]></title>
        <id>https://github.com/lightly-ai/lightly-train</id>
        <link href="https://github.com/lightly-ai/lightly-train"/>
        <updated>2025-12-08T11:50:04.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/50146475?v=4" width="64" height="64" alt=""/><br/><div>All-in-one training for vision models (YOLO, ViTs, RT-DETR, DINOv3): pretraining, fine-tuning, distillation.</div>]]></content>
        <author>
            <name>lightly-ai</name>
            <email>lightly-ai@noreply.github.com</email>
            <uri>https://github.com/lightly-ai</uri>
        </author>
        <published>2025-04-10T08:23:51.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[andykr1k/DinoV3Applied]]></title>
        <id>https://github.com/andykr1k/DinoV3Applied</id>
        <link href="https://github.com/andykr1k/DinoV3Applied"/>
        <updated>2025-12-08T07:30:10.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/69021102?u=7da65454f9bb80ea1ac18634f22dba9770912763&v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>andykr1k</name>
            <email>andykr1k@noreply.github.com</email>
            <uri>https://github.com/andykr1k</uri>
        </author>
        <published>2025-12-08T07:23:58.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[risebeforeshining/Dinov3-LMM: Dinov3-pretrained lmm based on LLaVA structure. The mlp]]></title>
        <id>https://github.com/risebeforeshining/Dinov3-LMM</id>
        <link href="https://github.com/risebeforeshining/Dinov3-LMM"/>
        <updated>2025-12-08T06:50:38.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/44262356?u=c11757ca9bc126d34c0e8254920cb76c444d565c&v=4" width="64" height="64" alt=""/><br/><div>Dinov3-pretrained lmm based on LLaVA structure. The mlp</div>]]></content>
        <author>
            <name>risebeforeshining</name>
            <email>risebeforeshining@noreply.github.com</email>
            <uri>https://github.com/risebeforeshining</uri>
        </author>
        <published>2025-12-08T06:37:59.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[tim-fan/festivity_maps: Mapping neighbourhood festivity levels with DINOv3]]></title>
        <id>https://github.com/tim-fan/festivity_maps</id>
        <link href="https://github.com/tim-fan/festivity_maps"/>
        <updated>2025-12-08T06:32:25.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/7835911?v=4" width="64" height="64" alt=""/><br/><div>Mapping neighbourhood festivity levels with DINOv3</div>]]></content>
        <author>
            <name>tim-fan</name>
            <email>tim-fan@noreply.github.com</email>
            <uri>https://github.com/tim-fan</uri>
        </author>
        <published>2025-11-24T04:06:04.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[CharlesChang012/3D-Semantic-Segmentation-Fusion: This repository implements a multi-modal 3D semantic segmentation and reconstruction system that fuses LiDAR point clouds and RGB images for autonomous scene understanding.]]></title>
        <id>https://github.com/CharlesChang012/3D-Semantic-Segmentation-Fusion</id>
        <link href="https://github.com/CharlesChang012/3D-Semantic-Segmentation-Fusion"/>
        <updated>2025-12-08T02:11:39.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/99932218?u=5e9953d299638b65e023c2c7a88050bfd030477b&v=4" width="64" height="64" alt=""/><br/><div>This repository implements a multi-modal 3D semantic segmentation and reconstruction system that fuses LiDAR point clouds and RGB images for autonomous scene understanding.</div>]]></content>
        <author>
            <name>CharlesChang012</name>
            <email>CharlesChang012@noreply.github.com</email>
            <uri>https://github.com/CharlesChang012</uri>
        </author>
        <published>2025-10-25T01:11:11.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Navifra-Bero/SAM3_DINOv3-Image-Matching]]></title>
        <id>https://github.com/Navifra-Bero/SAM3_DINOv3-Image-Matching</id>
        <link href="https://github.com/Navifra-Bero/SAM3_DINOv3-Image-Matching"/>
        <updated>2025-12-08T01:30:35.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/217902505?v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>Navifra-Bero</name>
            <email>Navifra-Bero@noreply.github.com</email>
            <uri>https://github.com/Navifra-Bero</uri>
        </author>
        <published>2025-12-08T01:30:31.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pratham-22/owlv2-dinov3-open-vocabulary-pipeline: Two-stage open-vocabulary vision pipeline combining OWLv2 detection with DINOv3 patch-level embeddings for zero-shot classification. Supports batched, GPU-accelerated inference, parallel object processing, cropped patch export, and detailed JSON + log outputs for research-grade analysis.]]></title>
        <id>https://github.com/Pratham-22/owlv2-dinov3-open-vocabulary-pipeline</id>
        <link href="https://github.com/Pratham-22/owlv2-dinov3-open-vocabulary-pipeline"/>
        <updated>2025-12-06T17:15:49.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/88884985?u=0d1cebf5947704141b9771b9d698f7cd0dcedd27&v=4" width="64" height="64" alt=""/><br/><div>Two-stage open-vocabulary vision pipeline combining OWLv2 detection with DINOv3 patch-level embeddings for zero-shot classification. Supports batched, GPU-accelerated inference, parallel object processing, cropped patch export, and detailed JSON + log outputs for research-grade analysis.</div>]]></content>
        <author>
            <name>Pratham-22</name>
            <email>Pratham-22@noreply.github.com</email>
            <uri>https://github.com/Pratham-22</uri>
        </author>
        <published>2025-12-06T04:04:28.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[devMuniz02/UDEM-CXR-Reporting-Thesis-2025: Multimodal chest X-ray diagnosis + AI report generation using DINOv3 and a GPT-based model with modified transformer attention. UDEM thesis project.]]></title>
        <id>https://github.com/devMuniz02/UDEM-CXR-Reporting-Thesis-2025</id>
        <link href="https://github.com/devMuniz02/UDEM-CXR-Reporting-Thesis-2025"/>
        <updated>2025-12-06T16:28:35.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/118771029?u=955fe98be3158a661f72095cd7d65fa8bd4b1282&v=4" width="64" height="64" alt=""/><br/><div>Multimodal chest X-ray diagnosis + AI report generation using DINOv3 and a GPT-based model with modified transformer attention. UDEM thesis project.</div>]]></content>
        <author>
            <name>devMuniz02</name>
            <email>devMuniz02@noreply.github.com</email>
            <uri>https://github.com/devMuniz02</uri>
        </author>
        <published>2025-06-06T16:10:17.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[hyuchi123/CVPDL_IP_CLIP_DINOv3: Á∑¥ÁøíÂæ©Âàª‰øÆÊîπhttps://github.com/LyWang12/IP-CLIP/tree/main]]></title>
        <id>https://github.com/hyuchi123/CVPDL_IP_CLIP_DINOv3</id>
        <link href="https://github.com/hyuchi123/CVPDL_IP_CLIP_DINOv3"/>
        <updated>2025-12-06T10:47:52.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/153170507?v=4" width="64" height="64" alt=""/><br/><div>Á∑¥ÁøíÂæ©Âàª‰øÆÊîπ<a href="https://github.com/LyWang12/IP-CLIP/tree/main" class="Link--inTextBlock">https://github.com/LyWang12/IP-CLIP/tree/main</a></div>]]></content>
        <author>
            <name>hyuchi123</name>
            <email>hyuchi123@noreply.github.com</email>
            <uri>https://github.com/hyuchi123</uri>
        </author>
        <published>2025-12-06T07:10:20.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[KostyalBalint/02456-deep-learning-final-project: DINOv3 based anomaly detection on MVTech dataset]]></title>
        <id>https://github.com/KostyalBalint/02456-deep-learning-final-project</id>
        <link href="https://github.com/KostyalBalint/02456-deep-learning-final-project"/>
        <updated>2025-12-05T21:37:01.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/10886602?u=3e19904ce8c9e389f638cd7bd3ca9ff43dc0bcb6&v=4" width="64" height="64" alt=""/><br/><div>DINOv3 based anomaly detection on MVTech dataset</div>]]></content>
        <author>
            <name>KostyalBalint</name>
            <email>KostyalBalint@noreply.github.com</email>
            <uri>https://github.com/KostyalBalint</uri>
        </author>
        <published>2025-11-09T10:26:28.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[jdiegomt12/zero-shot-anomaly-detection: Goal: Apply pre-trained foundation models (like DINOv3, Mirroring DINO, or SAM) to detect surface defects and irregular textures in industrial images ‚Äî specifically using the MVTec Anomaly Detection (AD) dataset).]]></title>
        <id>https://github.com/jdiegomt12/zero-shot-anomaly-detection</id>
        <link href="https://github.com/jdiegomt12/zero-shot-anomaly-detection"/>
        <updated>2025-12-05T20:53:50.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/234434219?v=4" width="64" height="64" alt=""/><br/><div>Goal: Apply pre-trained foundation models (like DINOv3, Mirroring DINO, or SAM) to detect surface defects and irregular textures in industrial images ‚Äî specifically using the MVTec Anomaly Detection (AD) dataset).</div>]]></content>
        <author>
            <name>jdiegomt12</name>
            <email>jdiegomt12@noreply.github.com</email>
            <uri>https://github.com/jdiegomt12</uri>
        </author>
        <published>2025-11-03T15:26:18.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[bryan-pakulski/xtractor: Unique video frame extractor using dinov3 - Building datasets for Computer Vision models.]]></title>
        <id>https://github.com/bryan-pakulski/xtractor</id>
        <link href="https://github.com/bryan-pakulski/xtractor"/>
        <updated>2025-12-05T13:29:47.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/15654375?u=a5d97cb93ed7abb95d36c5a913932e666031b064&v=4" width="64" height="64" alt=""/><br/><div>Unique video frame extractor using dinov3 - Building datasets for Computer Vision models.</div>]]></content>
        <author>
            <name>bryan-pakulski</name>
            <email>bryan-pakulski@noreply.github.com</email>
            <uri>https://github.com/bryan-pakulski</uri>
        </author>
        <published>2025-08-17T12:25:30.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[shreyaspulle98/SuperVision: Transfer learning for superconductor critical temperature prediction - DINOv3 + ALIGNN]]></title>
        <id>https://github.com/shreyaspulle98/SuperVision</id>
        <link href="https://github.com/shreyaspulle98/SuperVision"/>
        <updated>2025-12-05T11:22:55.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/199410260?v=4" width="64" height="64" alt=""/><br/><div>Transfer learning for superconductor critical temperature prediction - DINOv3 + ALIGNN</div>]]></content>
        <author>
            <name>shreyaspulle98</name>
            <email>shreyaspulle98@noreply.github.com</email>
            <uri>https://github.com/shreyaspulle98</uri>
        </author>
        <published>2025-11-24T18:36:44.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[ZachNK/ImgMatching_DINOv3: DINOv3 Image Matching (Docker Based)]]></title>
        <id>https://github.com/ZachNK/ImgMatching_DINOv3</id>
        <link href="https://github.com/ZachNK/ImgMatching_DINOv3"/>
        <updated>2025-12-05T05:58:54.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/26238447?v=4" width="64" height="64" alt=""/><br/><div>DINOv3 Image Matching (Docker Based)</div>]]></content>
        <author>
            <name>ZachNK</name>
            <email>ZachNK@noreply.github.com</email>
            <uri>https://github.com/ZachNK</uri>
        </author>
        <published>2025-10-20T08:44:10.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[ObedDzik/dinov3]]></title>
        <id>https://github.com/ObedDzik/dinov3</id>
        <link href="https://github.com/ObedDzik/dinov3"/>
        <updated>2025-12-05T00:20:59.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/70821652?u=572f3ad173921498edbbfc02d586bfffc72f5759&v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>ObedDzik</name>
            <email>ObedDzik@noreply.github.com</email>
            <uri>https://github.com/ObedDzik</uri>
        </author>
        <published>2025-12-05T00:14:41.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Saeedalgharib/DINOv3-SAM-FViT: Official implementation of the DINOv3‚ÄìSAM F-ViT dual-encoder framework for chest X-ray classification.]]></title>
        <id>https://github.com/Saeedalgharib/DINOv3-SAM-FViT</id>
        <link href="https://github.com/Saeedalgharib/DINOv3-SAM-FViT"/>
        <updated>2025-12-04T21:25:28.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/136626624?v=4" width="64" height="64" alt=""/><br/><div>Official implementation of the DINOv3‚ÄìSAM F-ViT dual-encoder framework for chest X-ray classification.</div>]]></content>
        <author>
            <name>Saeedalgharib</name>
            <email>Saeedalgharib@noreply.github.com</email>
            <uri>https://github.com/Saeedalgharib</uri>
        </author>
        <published>2025-12-04T10:30:25.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[ColdVI/Fish-Segmentation-DINOv3: DINOv3-based semantic segmentation pipeline for large-scale fish datasets. Includes data loading, preprocessing, model inference, training, evaluation, and advanced visualization of segmentation results.]]></title>
        <id>https://github.com/ColdVI/Fish-Segmentation-DINOv3</id>
        <link href="https://github.com/ColdVI/Fish-Segmentation-DINOv3"/>
        <updated>2025-12-04T21:05:15.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/126476389?u=be6e69e5a096dd1d251d599a168641d36edabda5&v=4" width="64" height="64" alt=""/><br/><div>DINOv3-based semantic segmentation pipeline for large-scale fish datasets. Includes data loading, preprocessing, model inference, training, evaluation, and advanced visualization of segmentation results.</div>]]></content>
        <author>
            <name>ColdVI</name>
            <email>ColdVI@noreply.github.com</email>
            <uri>https://github.com/ColdVI</uri>
        </author>
        <published>2025-12-04T09:40:40.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[getrichthroughcode/dinov3-isic2018-segmentation: Comparing classic segmentation networks to networks that have dinov3 as a backbone]]></title>
        <id>https://github.com/getrichthroughcode/dinov3-isic2018-segmentation</id>
        <link href="https://github.com/getrichthroughcode/dinov3-isic2018-segmentation"/>
        <updated>2025-12-04T14:27:21.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/113793273?v=4" width="64" height="64" alt=""/><br/><div>Comparing classic segmentation networks to networks that have dinov3 as a backbone</div>]]></content>
        <author>
            <name>getrichthroughcode</name>
            <email>getrichthroughcode@noreply.github.com</email>
            <uri>https://github.com/getrichthroughcode</uri>
        </author>
        <published>2025-09-24T18:53:13.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[ji-da-cs/Tennis-Stroke-Classifier: CS5100 Project: Create a classifier for different tennis strokes using dinoV3, and analyze stroke form using pose estimation]]></title>
        <id>https://github.com/ji-da-cs/Tennis-Stroke-Classifier</id>
        <link href="https://github.com/ji-da-cs/Tennis-Stroke-Classifier"/>
        <updated>2025-12-04T05:44:09.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/247511394?v=4" width="64" height="64" alt=""/><br/><div>CS5100 Project: Create a classifier for different tennis strokes using dinoV3, and analyze stroke form using pose estimation</div>]]></content>
        <author>
            <name>ji-da-cs</name>
            <email>ji-da-cs@noreply.github.com</email>
            <uri>https://github.com/ji-da-cs</uri>
        </author>
        <published>2025-12-03T04:24:51.000Z</published>
    </entry>
</feed>