<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://cdekort.github.io/github-search-rss/dinov3-repos.rss</id>
    <title>DINOv3 Repositories</title>
    <updated>2026-02-06T00:30:55.100Z</updated>
    <generator>github-search-rss</generator>
    <link rel="alternate" href="https://cdekort.github.io/github-search-rss/dinov3-repos.rss"/>
    <subtitle>DINOv3 Repositories on GitHub</subtitle>
    <rights>github-search-rss</rights>
    <entry>
        <title type="html"><![CDATA[dlidgett/AD-DINOv3: üîç Enhance anomaly detection with AD-DINOv3, a framework adapting DINOv3 for zero-shot scenarios through advanced calibration techniques.]]></title>
        <id>https://github.com/dlidgett/AD-DINOv3</id>
        <link href="https://github.com/dlidgett/AD-DINOv3"/>
        <updated>2026-02-05T23:55:06.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/66205403?v=4" width="64" height="64" alt=""/><br/><div>üîç Enhance anomaly detection with AD-DINOv3, a framework adapting DINOv3 for zero-shot scenarios through advanced calibration techniques.</div>]]></content>
        <author>
            <name>dlidgett</name>
            <email>dlidgett@noreply.github.com</email>
            <uri>https://github.com/dlidgett</uri>
        </author>
        <published>2020-05-31T11:42:52.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[LukaDarsalia/colormnet_dinov3]]></title>
        <id>https://github.com/LukaDarsalia/colormnet_dinov3</id>
        <link href="https://github.com/LukaDarsalia/colormnet_dinov3"/>
        <updated>2026-02-05T23:47:05.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/29729836?u=d5b98a781f2e3e93ae1b3b9229177256600b097a&v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>LukaDarsalia</name>
            <email>LukaDarsalia@noreply.github.com</email>
            <uri>https://github.com/LukaDarsalia</uri>
        </author>
        <published>2026-02-03T17:34:48.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nacho4412gg/dinov3]]></title>
        <id>https://github.com/Nacho4412gg/dinov3</id>
        <link href="https://github.com/Nacho4412gg/dinov3"/>
        <updated>2026-02-05T21:38:46.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/204909044?v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>Nacho4412gg</name>
            <email>Nacho4412gg@noreply.github.com</email>
            <uri>https://github.com/Nacho4412gg</uri>
        </author>
        <published>2026-01-11T18:24:22.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[GIS-Remote-Sensing-Goettingen/dinov3-LWF-Segmentation-erosion]]></title>
        <id>https://github.com/GIS-Remote-Sensing-Goettingen/dinov3-LWF-Segmentation-erosion</id>
        <link href="https://github.com/GIS-Remote-Sensing-Goettingen/dinov3-LWF-Segmentation-erosion"/>
        <updated>2026-02-05T18:05:23.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/231213492?v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>GIS-Remote-Sensing-Goettingen</name>
            <email>GIS-Remote-Sensing-Goettingen@noreply.github.com</email>
            <uri>https://github.com/GIS-Remote-Sensing-Goettingen</uri>
        </author>
        <published>2026-01-26T13:43:19.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[GIS-Remote-Sensing-Goettingen/Dinov3-LWF-Segmentation]]></title>
        <id>https://github.com/GIS-Remote-Sensing-Goettingen/Dinov3-LWF-Segmentation</id>
        <link href="https://github.com/GIS-Remote-Sensing-Goettingen/Dinov3-LWF-Segmentation"/>
        <updated>2026-02-05T18:01:51.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/231213492?v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>GIS-Remote-Sensing-Goettingen</name>
            <email>GIS-Remote-Sensing-Goettingen@noreply.github.com</email>
            <uri>https://github.com/GIS-Remote-Sensing-Goettingen</uri>
        </author>
        <published>2026-02-02T13:58:10.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[lightly-ai/lightly-train: All-in-one training for vision models (YOLO, ViTs, RT-DETR, DINOv3): pretraining, fine-tuning, distillation.]]></title>
        <id>https://github.com/lightly-ai/lightly-train</id>
        <link href="https://github.com/lightly-ai/lightly-train"/>
        <updated>2026-02-05T15:18:04.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/50146475?v=4" width="64" height="64" alt=""/><br/><div>All-in-one training for vision models (YOLO, ViTs, RT-DETR, DINOv3): pretraining, fine-tuning, distillation.</div>]]></content>
        <author>
            <name>lightly-ai</name>
            <email>lightly-ai@noreply.github.com</email>
            <uri>https://github.com/lightly-ai</uri>
        </author>
        <published>2025-04-10T08:23:51.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[johnamit/motoreid: A deep learning pipeline for MotoGP team detection, tracking, and re-identification from race broadcast footage. This system combines YOLOv8 for robust object detection with DINOv3 (Vision Transformer) embeddings for semantic team classification.]]></title>
        <id>https://github.com/johnamit/motoreid</id>
        <link href="https://github.com/johnamit/motoreid"/>
        <updated>2026-02-05T15:09:02.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/75620312?u=8806c49054eb4620ae51aa548c5f08997486b21e&v=4" width="64" height="64" alt=""/><br/><div>A deep learning pipeline for MotoGP team detection, tracking, and re-identification from race broadcast footage. This system combines YOLOv8 for robust object detection with DINOv3 (Vision Transformer) embeddings for semantic team classification.</div>]]></content>
        <author>
            <name>johnamit</name>
            <email>johnamit@noreply.github.com</email>
            <uri>https://github.com/johnamit</uri>
        </author>
        <published>2026-01-14T18:42:24.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[RomanRes/CSIRO-Biomass-Prediction-using-DINOv3: The project focuses on modern computer vision techniques and demonstrates how large self-supervised vision transformers can be adapted efficiently for regression tasks using parameter-efficient fine-tuning.]]></title>
        <id>https://github.com/RomanRes/CSIRO-Biomass-Prediction-using-DINOv3</id>
        <link href="https://github.com/RomanRes/CSIRO-Biomass-Prediction-using-DINOv3"/>
        <updated>2026-02-05T13:17:20.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/62020123?u=46315ce64061756a2b722c9dc3857a3ff440baae&v=4" width="64" height="64" alt=""/><br/><div>The project focuses on modern computer vision techniques and demonstrates how large self-supervised vision transformers can be adapted efficiently for regression tasks using parameter-efficient fine-tuning.</div>]]></content>
        <author>
            <name>RomanRes</name>
            <email>RomanRes@noreply.github.com</email>
            <uri>https://github.com/RomanRes</uri>
        </author>
        <published>2026-02-02T19:49:23.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[jayd972/Multi-Agent-dinov3-explainable-tumor-detection-framework]]></title>
        <id>https://github.com/jayd972/Multi-Agent-dinov3-explainable-tumor-detection-framework</id>
        <link href="https://github.com/jayd972/Multi-Agent-dinov3-explainable-tumor-detection-framework"/>
        <updated>2026-02-05T11:33:04.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/75724261?u=ec9417a3cccd67a77f38c9ae073a07dd8af99e9e&v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>jayd972</name>
            <email>jayd972@noreply.github.com</email>
            <uri>https://github.com/jayd972</uri>
        </author>
        <published>2026-02-05T11:01:15.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[wen146146/dinov3-detr]]></title>
        <id>https://github.com/wen146146/dinov3-detr</id>
        <link href="https://github.com/wen146146/dinov3-detr"/>
        <updated>2026-02-05T07:15:46.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/250138186?v=4" width="64" height="64" alt=""/><br/><div></div>]]></content>
        <author>
            <name>wen146146</name>
            <email>wen146146@noreply.github.com</email>
            <uri>https://github.com/wen146146</uri>
        </author>
        <published>2026-02-05T00:52:44.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Thanghuynh2808/MORAD_MAI: Automated Planogram Compliance system for retail shelves. Features: Panorama Stitching, Zero-shot SKU Detection (YOLO, DINOv3, LightGlue), and LLM-powered rule validation. Optimized for large-scale grocery shelf analysis in Vietnam.]]></title>
        <id>https://github.com/Thanghuynh2808/MORAD_MAI</id>
        <link href="https://github.com/Thanghuynh2808/MORAD_MAI"/>
        <updated>2026-02-04T04:12:25.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/156525690?u=859091d4e8fe94e40ba8c4ba1324563f3228fda3&v=4" width="64" height="64" alt=""/><br/><div>Automated Planogram Compliance system for retail shelves. Features: Panorama Stitching, Zero-shot SKU Detection (YOLO, DINOv3, LightGlue), and LLM-powered rule validation. Optimized for large-scale grocery shelf analysis in Vietnam.</div>]]></content>
        <author>
            <name>Thanghuynh2808</name>
            <email>Thanghuynh2808@noreply.github.com</email>
            <uri>https://github.com/Thanghuynh2808</uri>
        </author>
        <published>2026-02-03T02:40:51.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[yberreby/dinov3-in1k-probes: Pretrained ImageNet-1k linear classification heads for DINOv3 ViT (S/S+/B/L/H+).]]></title>
        <id>https://github.com/yberreby/dinov3-in1k-probes</id>
        <link href="https://github.com/yberreby/dinov3-in1k-probes"/>
        <updated>2026-02-04T03:36:59.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/5556521?u=d6ca49ea6294af95c95c75ad2c94620fd8950381&v=4" width="64" height="64" alt=""/><br/><div>Pretrained ImageNet-1k linear classification heads for DINOv3 ViT (S/S+/B/L/H+).</div>]]></content>
        <author>
            <name>yberreby</name>
            <email>yberreby@noreply.github.com</email>
            <uri>https://github.com/yberreby</uri>
        </author>
        <published>2025-11-16T20:03:12.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[talhabw/autoseg: an annotation tool for segmentation models, with SAM3 integration and automatic propagation using image encoder models (DINOv3 and Pixio)]]></title>
        <id>https://github.com/talhabw/autoseg</id>
        <link href="https://github.com/talhabw/autoseg"/>
        <updated>2026-02-03T19:52:42.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/56639619?u=1a98caa2017443e235e7b84fc18a7182ec8a8a18&v=4" width="64" height="64" alt=""/><br/><div>an annotation tool for segmentation models, with SAM3 integration and automatic propagation using image encoder models (DINOv3 and Pixio)</div>]]></content>
        <author>
            <name>talhabw</name>
            <email>talhabw@noreply.github.com</email>
            <uri>https://github.com/talhabw</uri>
        </author>
        <published>2025-12-27T19:05:03.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[aihpi/tool-dinov3-embeddings-api: FastAPI service for DINOv3 image embeddings, containerized for GPU/CPU and Kubernetes.]]></title>
        <id>https://github.com/aihpi/tool-dinov3-embeddings-api</id>
        <link href="https://github.com/aihpi/tool-dinov3-embeddings-api"/>
        <updated>2026-02-03T19:00:58.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/149687007?v=4" width="64" height="64" alt=""/><br/><div>FastAPI service for DINOv3 image embeddings, containerized for GPU/CPU and Kubernetes.</div>]]></content>
        <author>
            <name>aihpi</name>
            <email>aihpi@noreply.github.com</email>
            <uri>https://github.com/aihpi</uri>
        </author>
        <published>2026-02-03T15:25:45.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[tb-tian/AIC2025-VideoRetrieval-float97: Multimodal video retrieval system for HCMC AI Challenge 2025 | SigLIP Keyframe extraction + DINOv3 + WhisperX]]></title>
        <id>https://github.com/tb-tian/AIC2025-VideoRetrieval-float97</id>
        <link href="https://github.com/tb-tian/AIC2025-VideoRetrieval-float97"/>
        <updated>2026-02-03T16:53:45.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/145255003?v=4" width="64" height="64" alt=""/><br/><div>Multimodal video retrieval system for HCMC AI Challenge 2025 | SigLIP Keyframe extraction + DINOv3 + WhisperX</div>]]></content>
        <author>
            <name>tb-tian</name>
            <email>tb-tian@noreply.github.com</email>
            <uri>https://github.com/tb-tian</uri>
        </author>
        <published>2025-07-23T11:51:00.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[zgcr/SimpleAICV_pytorch_training_examples: SimpleAICV:pytorch training examples.]]></title>
        <id>https://github.com/zgcr/SimpleAICV_pytorch_training_examples</id>
        <link href="https://github.com/zgcr/SimpleAICV_pytorch_training_examples"/>
        <updated>2026-02-05T07:26:54.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/19390485?u=d9f77e6cad56ea1c0c19ea2852b7833c76d2cf4a&v=4" width="64" height="64" alt=""/><br/><div>SimpleAICV:pytorch training examples.</div>]]></content>
        <author>
            <name>zgcr</name>
            <email>zgcr@noreply.github.com</email>
            <uri>https://github.com/zgcr</uri>
        </author>
        <published>2020-05-31T05:37:26.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sonam525/PEFT-Fine-tuning-cows: Exploring the power of PEFT by systematically comparing three approaches for nine-class dairy cow behavior classification: training from scratch (ResNet-18, ViT-Small), frozen feature extraction, and parameter-efficient fine-tuning (PEFT) of the DINOv3 foundation model (6.7 billion parameters)]]></title>
        <id>https://github.com/Sonam525/PEFT-Fine-tuning-cows</id>
        <link href="https://github.com/Sonam525/PEFT-Fine-tuning-cows"/>
        <updated>2026-02-02T18:18:50.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/149631650?v=4" width="64" height="64" alt=""/><br/><div>Exploring the power of PEFT by systematically comparing three approaches for nine-class dairy cow behavior classification: training from scratch (ResNet-18, ViT-Small), frozen feature extraction, and parameter-efficient fine-tuning (PEFT) of the DINOv3 foundation model (6.7 billion parameters)</div>]]></content>
        <author>
            <name>Sonam525</name>
            <email>Sonam525@noreply.github.com</email>
            <uri>https://github.com/Sonam525</uri>
        </author>
        <published>2026-02-02T14:04:04.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[DanilaAniva/kitmatch: Unique tool matching app that makes you happy when you see bbox on every tool; Triton+FastAPI deplyoment; Yolov11, DinoV3 experiments; React frontend. ]]></title>
        <id>https://github.com/DanilaAniva/kitmatch</id>
        <link href="https://github.com/DanilaAniva/kitmatch"/>
        <updated>2026-02-01T17:44:45.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/128606792?u=267a157e60ef4a882150eea15b3a001c3bf53871&v=4" width="64" height="64" alt=""/><br/><div>Unique tool matching app that makes you happy when you see bbox on every tool; Triton+FastAPI deplyoment; Yolov11, DinoV3 experiments; React frontend. </div>]]></content>
        <author>
            <name>DanilaAniva</name>
            <email>DanilaAniva@noreply.github.com</email>
            <uri>https://github.com/DanilaAniva</uri>
        </author>
        <published>2025-10-16T17:49:02.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[CaedenMotley/SeeRex: Work in progress. Tools and experiments for understanding DINOv3‚Äôs internal representations.]]></title>
        <id>https://github.com/CaedenMotley/SeeRex</id>
        <link href="https://github.com/CaedenMotley/SeeRex"/>
        <updated>2026-02-01T00:44:28.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/134373233?u=28e25f10907e080fec3b444004d9238e31da2bc2&v=4" width="64" height="64" alt=""/><br/><div>Work in progress. Tools and experiments for understanding DINOv3‚Äôs internal representations.</div>]]></content>
        <author>
            <name>CaedenMotley</name>
            <email>CaedenMotley@noreply.github.com</email>
            <uri>https://github.com/CaedenMotley</uri>
        </author>
        <published>2025-10-29T00:29:50.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[drtiwari/OmniMatch_CV: A Zero-Shot Universal Object Locator using DINOv3 and FAISS. Features a Human-in-the-Loop Streamlit interface for real-time target calibration, sliding-window inference, and automated metadata logging. Optimized for industrial anomaly detection.]]></title>
        <id>https://github.com/drtiwari/OmniMatch_CV</id>
        <link href="https://github.com/drtiwari/OmniMatch_CV"/>
        <updated>2026-01-31T18:44:15.000Z</updated>
        <content type="html"><![CDATA[<img src="https://avatars.githubusercontent.com/u/54511186?u=2901ba2b42f9e1f11221c888cf51b785e940a929&v=4" width="64" height="64" alt=""/><br/><div>A Zero-Shot Universal Object Locator using DINOv3 and FAISS. Features a Human-in-the-Loop Streamlit interface for real-time target calibration, sliding-window inference, and automated metadata logging. Optimized for industrial anomaly detection.</div>]]></content>
        <author>
            <name>drtiwari</name>
            <email>drtiwari@noreply.github.com</email>
            <uri>https://github.com/drtiwari</uri>
        </author>
        <published>2026-01-31T18:33:03.000Z</published>
    </entry>
</feed>